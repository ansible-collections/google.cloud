#!/usr/bin/python
# -*- coding: utf-8 -*-
#
# Copyright (C) 2017-2026 Google
# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)
# ----------------------------------------------------------------------------
#
#     ***     AUTO GENERATED CODE    ***    Type: MMv1     ***
#
# ----------------------------------------------------------------------------
#
#     This file is automatically generated by Magic Modules and manual
#     changes will be clobbered when the file is regenerated.
#
# ----------------------------------------------------------------------------
#

from __future__ import absolute_import, division, print_function

__metaclass__ = type

################################################################################
# Documentation
################################################################################

ANSIBLE_METADATA = {
    "metadata_version": "1.1",
    "status": ["preview"],
    "supported_by": "community",
}

DOCUMENTATION = r"""
---
author:
  - Google Inc. (@googlecloudplatform)
description:
  - A collection of DataItems and Annotations on them.
extends_documentation_fragment:
  - google.cloud.gcp
module: gcp_vertexai_dataset
notes:
  - 'API Reference: U(https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.datasets)'
  - 'Official Documentation Guide: U(https://cloud.google.com/vertex-ai/docs)'
options:
  display_name:
    description:
      - The user-defined name of the Dataset.
      - The name can be up to 128 characters long and can be consist of any UTF-8 characters.
    required: true
    type: str
  encryption_spec:
    description:
      - Customer-managed encryption key spec for a Dataset.
      - If set, this Dataset and all sub-resources of this Dataset will be secured by this key.
    suboptions:
      kms_key_name:
        description:
          - The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource.
          - 'Has the form: projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key.'
          - The key needs to be in the same region as where the resource is created.
        type: str
    type: dict
  labels:
    description:
      - A set of key/value label pairs to assign to this Workflow.
    type: dict
  metadata_schema_uri:
    description:
      - Points to a YAML file stored on Google Cloud Storage describing additional information about the Dataset.
      - The schema is defined as an OpenAPI 3.0.2 Schema Object.
      - The schema files that can be used here are found in gs://google-cloud-aiplatform/schema/dataset/metadata/.
    required: true
    type: str
  region:
    description:
      - The region of the dataset.
      - eg us-central1.
    type: str
  state:
    choices:
      - present
      - absent
    default: present
    description:
      - Whether the resource should exist in GCP.
    type: str
requirements:
  - python >= 3.8
  - requests >= 2.18.4
  - google-auth >= 2.25.1
short_description: Creates a GCP VertexAI.Dataset resource
"""

EXAMPLES = r"""
- name: Create dataset
  google.cloud.gcp_vertexai_dataset:
    state: present
    display_name: "{{ resource_name }}"
    metadata_schema_uri: "gs://google-cloud-aiplatform/schema/dataset/metadata/image_1.0.0.yaml"
    region: us-central1
    project: "{{ gcp_project }}"
    auth_kind: "{{ gcp_cred_kind }}"
    service_account_file: "{{ gcp_cred_file }}"
  register: _myds

- name: Run assertions
  ansible.builtin.assert:
    that:
      - _myds.changed == true

- name: Update dataset
  google.cloud.gcp_vertexai_dataset:
    state: present
    display_name: "{{ resource_name }}"
    metadata_schema_uri: "gs://google-cloud-aiplatform/schema/dataset/metadata/image_1.0.0.yaml"
    labels:
      env: test
    region: us-central1
    project: "{{ gcp_project }}"
    auth_kind: "{{ gcp_cred_kind }}"
    service_account_file: "{{ gcp_cred_file }}"
  register: _myds

- name: Run assertions
  ansible.builtin.assert:
    that:
      - _myds.changed == true
      - _myds.labels | length > 0
      - _myds.labels.env == "test"

- name: Destroy dataset
  google.cloud.gcp_vertexai_dataset:
    state: absent
    display_name: "{{ resource_name }}"
    metadata_schema_uri: "gs://google-cloud-aiplatform/schema/dataset/metadata/image_1.0.0.yaml"
    region: us-central1
    project: "{{ gcp_project }}"
    auth_kind: "{{ gcp_cred_kind }}"
    service_account_file: "{{ gcp_cred_file }}"
"""

RETURN = r"""
changed:
  description: Whether the resource was changed.
  returned: always
  type: bool
createTime:
  description:
    - The timestamp of when the dataset was created in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine fractional digits.
  returned: success
  type: str
name:
  description:
    - The resource name of the Dataset.
    - This value is set by Google.
  returned: success
  type: str
state:
  description: The current state of the resource.
  returned: always
  type: str
updateTime:
  description:
    - >-
      The timestamp of when the dataset was last updated in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine fractional

      digits.
  returned: success
  type: str
"""

################################################################################
# Imports
################################################################################

from ansible_collections.google.cloud.plugins.module_utils import gcp_utils as gcp
import types

# BEGIN Custom imports

# END Custom imports


def build_link(module_params, uri):
    params = module_params.copy()

    return ("https://{region}-aiplatform.googleapis.com/v1/" + uri).format(**params)


class EncryptionSpec(gcp.Resource):
    def _request(self):
        return {
            "kmsKeyName": self.request.get("kms_key_name"),
        }

    def _response(self):
        return {
            "kmsKeyName": self.response.get("kmsKeyName"),
        }


class VertexAI(gcp.Resource):
    def _request(self):
        return {
            "displayName": self.request.get("display_name"),
            "encryptionSpec": gcp.remove_empties(
                EncryptionSpec(self.request.get("encryption_spec", {})).to_request()
            ),  # remove empty values
            "labels": self.request.get("labels"),
            "metadataSchemaUri": self.request.get("metadata_schema_uri"),
        }

    def _response(self):
        return {
            "createTime": self.response.get("createTime"),
            "displayName": self.response.get("displayName"),
            "encryptionSpec": EncryptionSpec().from_response(self.response.get("encryptionSpec", {})),
            "labels": self.response.get("labels"),
            "metadataSchemaUri": self.response.get("metadataSchemaUri"),
            "name": self.response.get("name"),
            "updateTime": self.response.get("updateTime"),
        }


################################################################################
# Main
################################################################################


def encode(self, obj):
    """
    This is a function bound to the main resource object. Its input is the object returned from to_request()
    and it mutates it before it is sent to the API.
    """
    return obj


def decode(self, obj):
    """
    This is a function bound to the main resource object. Its input is the object returned from from_response()
    and it mutates it before it is returned to the module caller.
    """
    return obj


def main():
    """Main function"""

    module = gcp.Module(
        argument_spec=dict(
            state=dict(
                type="str",
                default="present",
                choices=["present", "absent"],
            ),
            display_name=dict(
                type="str",
                required=True,
            ),
            encryption_spec=dict(
                type="dict",
                options=dict(
                    kms_key_name=dict(
                        type="str",
                        no_log=False,
                    )
                ),
            ),
            labels=dict(
                type="dict",
            ),
            metadata_schema_uri=dict(
                type="str",
                required=True,
            ),
            region=dict(
                type="str",
            ),
        )
    )

    if not module.params["scopes"]:
        module.params["scopes"] = ["https://www.googleapis.com/auth/cloud-platform"]

    state = module.params["state"]
    changed = False
    op_configs = gcp.ResourceOpConfigs(
        {
            "base_url": gcp.ResourceOpConfig(
                **{
                    "uri": "projects/{project}/locations/{region}/datasets",
                    "async_uri": "",
                    "verb": "GET",
                    "timeout_minutes": 0,
                }
            ),
            "create": gcp.ResourceOpConfig(
                **{
                    "uri": "projects/{project}/locations/{region}/datasets",
                    "async_uri": "{op_id}",
                    "verb": "POST",
                    "timeout_minutes": 20,
                }
            ),
            "delete": gcp.ResourceOpConfig(
                **{"uri": "{name}", "async_uri": "{op_id}", "verb": "DELETE", "timeout_minutes": 20}
            ),
            "read": gcp.ResourceOpConfig(**{"uri": "{name}", "async_uri": "", "verb": "GET", "timeout_minutes": 0}),
            "update": gcp.ResourceOpConfig(
                **{"uri": "{name}", "async_uri": "", "verb": "PATCH", "timeout_minutes": 20}
            ),
        }
    )

    params = gcp.remove_nones(module.params)
    resource = VertexAI(params, module=module, product="VertexAI", kind="vertexai#dataset")
    read_uri = op_configs.read.uri

    resource._state = state  # store the state in the resource object
    # Bind the encode and decode functions to the resource object
    resource.encode_func = types.MethodType(encode, resource)
    resource.decode_func = types.MethodType(decode, resource)

    custom_diff = None  # Set this variable if you want to implement custom diff logic

    # --------- BEGIN pre-read custom code ---------
    # for this module, we're hitting the list endpoint and filtering on display name
    read_uri = f"{op_configs.base_url.uri}?filter=displayName={params.get("display_name")}"

    # --------- END pre-read custom code ---------

    read_url = build_link(params, read_uri)
    existing_obj = resource.get(read_url, allow_not_found=True) or {}
    new_obj = {}
    gcp.debug(module, existing=existing_obj, post=False)

    # --------- BEGIN post-read custom code ---------
    # if there are existing datasets, the call would have returned a list
    if not gcp.empty(existing_obj):
        for ds in existing_obj.get("datasets", []):
            if ds.get("displayName") == params.get("display_name"):
                existing_obj = ds
                break

    # --------- END post-read custom code ---------

    if custom_diff is not None:
        is_different = custom_diff
    else:
        is_different = resource.diff(gcp.remove_empties(existing_obj))
    gcp.debug(
        module,
        request=gcp.remove_empties(resource.to_request()),
        existing=existing_obj,
        post=True,
        is_different=is_different,
    )

    if gcp.empty(existing_obj):
        if state == "present":
            create_uri = op_configs.create.uri
            create_async_uri = op_configs.create.async_uri
            try:
                # --------- BEGIN create code ---------
                is_async = create_async_uri != ""
                create_link = build_link(params, create_uri)
                create_retries = op_configs.create.timeout
                create_func = getattr(resource, op_configs.create.verb)
                async_create_func = getattr(resource, op_configs.create.verb + "_async")
                async_create_link = build_link(params, "") + create_async_uri
                gcp.debug(
                    module,
                    msg="Creating resource",
                    create_link=create_link,
                    async_create_link=async_create_link,
                    is_async=is_async,
                )

                if is_async:
                    new_obj = async_create_func(create_link, async_link=async_create_link, retries=create_retries)
                else:
                    new_obj = create_func(create_link)
                gcp.debug(module, new=new_obj, action="create", post=False)
                gcp.debug(module, new=new_obj, action="create", post=True)
                # --------- END create code ---------
            except Exception as e:
                module.fail_json(msg=str(e))

            changed = True
        else:
            pass  # nothing to do
    else:
        if state == "absent":
            delete_uri = op_configs.delete.uri
            delete_async_uri = op_configs.delete.async_uri
            try:
                # --------- BEGIN delete code ---------
                # --------- BEGIN pre-delete custom code ---------
                # need to set to the required parameter "name" to the existing resource name
                params["name"] = existing_obj["name"]
                # --------- END pre-delete custom code ---------
                is_async = delete_async_uri != ""
                delete_link = build_link(params, delete_uri)
                delete_retries = op_configs.delete.timeout
                delete_func = getattr(resource, op_configs.delete.verb)
                async_delete_func = getattr(resource, op_configs.delete.verb + "_async")
                async_delete_link = build_link(params, "") + delete_async_uri
                gcp.debug(
                    module,
                    msg="Destroying resource",
                    delete_link=delete_link,
                    async_delete_link=async_delete_link,
                    is_async=is_async,
                )
                if is_async:
                    new_obj = async_delete_func(delete_link, async_link=async_delete_link, retries=delete_retries)
                else:
                    new_obj = delete_func(delete_link)
                # --------- END delete code ---------
            except Exception as e:
                module.fail_json(msg=str(e))

            changed = True
        else:
            if is_different:
                update_uri = op_configs.update.uri
                update_async_uri = op_configs.update.async_uri
                try:
                    # --------- BEGIN update code ---------
                    # --------- BEGIN pre-update custom code ---------
                    # need to set to the required parameter "name" to the existing resource name
                    params["name"] = existing_obj["name"]

                    # need to build the updateMask for the fields in our module
                    update_uri += f"?updateMask=labels,{','.join(resource.dot_fields())}"

                    # --------- END pre-update custom code ---------
                    is_async = update_async_uri != ""
                    update_link = build_link(params, update_uri)
                    update_retries = op_configs.update.timeout
                    update_func = getattr(resource, op_configs.update.verb)
                    async_update_func = getattr(resource, op_configs.update.verb + "_async")
                    async_update_link = build_link(params, "") + update_async_uri
                    gcp.debug(
                        module,
                        msg="Updating resource",
                        update_link=update_link,
                        async_update_link=async_update_link,
                        is_async=is_async,
                    )
                    if is_async:
                        new_obj = async_update_func(update_link, async_link=async_update_link, retries=update_retries)
                    else:
                        new_obj = update_func(update_link)
                    gcp.debug(module, new=new_obj, action="update", post=False)
                    gcp.debug(module, new=new_obj, action="update", post=True)
                    # --------- END update code ---------
                except Exception as e:
                    module.fail_json(msg=str(e))

                changed = True
            else:
                new_obj = existing_obj

    new_obj.update({"changed": changed})
    module.exit_json(**new_obj)


if __name__ == "__main__":
    main()
