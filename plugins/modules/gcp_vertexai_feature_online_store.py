#!/usr/bin/python
# -*- coding: utf-8 -*-
#
# Copyright (C) 2017-2026 Google
# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)
# ----------------------------------------------------------------------------
#
#     ***     AUTO GENERATED CODE    ***    Type: MMv1     ***
#
# ----------------------------------------------------------------------------
#
#     This file is automatically generated by Magic Modules and manual
#     changes will be clobbered when the file is regenerated.
#
# ----------------------------------------------------------------------------
#

from __future__ import absolute_import, division, print_function

__metaclass__ = type

################################################################################
# Documentation
################################################################################

ANSIBLE_METADATA = {
    "metadata_version": "1.1",
    "status": ["preview"],
    "supported_by": "community",
}

DOCUMENTATION = r"""
---
author:
  - Google Inc. (@googlecloudplatform)
description:
  - >-
    Vertex AI Feature Online Store provides a centralized repository for serving ML features and embedding indexes at low latency. The Feature

    Online Store is a top-level container.
extends_documentation_fragment:
  - google.cloud.gcp
module: gcp_vertexai_feature_online_store
notes:
  - 'API Reference: U(https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.featureOnlineStores)'
  - 'Official Documentation Guide: U(https://cloud.google.com/vertex-ai/docs)'
options:
  bigtable:
    description:
      - Settings for Cloud Bigtable instance that will be created to serve featureValues for all FeatureViews under this FeatureOnlineStore.
    suboptions:
      auto_scaling:
        description:
          - Autoscaling config applied to Bigtable Instance.
        required: true
        suboptions:
          cpu_utilization_target:
            description:
              - A percentage of the cluster's CPU capacity.
              - Can be from 10% to 80%.
              - When a cluster's CPU utilization exceeds the target that you have set, Bigtable immediately adds nodes to the cluster.
              - When CPU utilization is substantially lower than the target, Bigtable removes nodes.
              - If not set will default to 50%.
            type: int
          max_node_count:
            description:
              - The maximum number of nodes to scale up to.
              - Must be greater than or equal to minNodeCount, and less than or equal to 10 times of 'minNodeCount'.
            required: true
            type: int
          min_node_count:
            description:
              - The minimum number of nodes to scale down to.
              - Must be greater than or equal to 1.
            required: true
            type: int
        type: dict
      enable_direct_bigtable_access:
        description:
          - If true, enable direct access to the Bigtable instance.
        type: bool
      zone:
        description:
          - The zone where the Bigtable instance will be created.
        type: str
    type: dict
  dedicated_serving_endpoint:
    description:
      - The dedicated serving endpoint for this FeatureOnlineStore, which is different from common vertex service endpoint.
      - Only need to be set when you choose Optimized storage type or enable EmbeddingManagement.
      - Will use public endpoint by default.
    suboptions:
      private_service_connect_config:
        description:
          - Private service connect config.
        suboptions:
          enable_private_service_connect:
            description:
              - If set to true, customers will use private service connection to send request.
              - Otherwise, the connection will set to public endpoint.
            required: true
            type: bool
          project_allowlist:
            description:
              - A list of Projects from which the forwarding rule will target the service attachment.
            elements: str
            type: list
        type: dict
      public_endpoint_domain_name:
        description:
          - Domain name to use for this FeatureOnlineStore.
        type: str
      service_attachment:
        description:
          - Name of the service attachment resource.
          - Applicable only if private service connect is enabled and after FeatureViewSync is created.
        type: str
    type: dict
  embedding_management:
    description:
      - The settings for embedding management in FeatureOnlineStore.
      - Embedding management can only be set for BigTable.
      - It is enabled by default for optimized storagetype.
    suboptions:
      enabled:
        description:
          - Enable embedding management.
        type: bool
    type: dict
  encryption_spec:
    description:
      - If set, both of the online and offline data storage will be secured by this key.
    suboptions:
      kms_key_name:
        description:
          - The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource.
          - 'Has the form: projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key.'
          - The key needs to be in the same region as where the compute resource is created.
        required: true
        type: str
    type: dict
  force_destroy:
    default: false
    description:
      - If set to true, any FeatureViews and Features for this FeatureOnlineStore will also be deleted.
    type: bool
  labels:
    description:
      - The labels with user-defined metadata to organize your feature online stores.
    type: dict
  name:
    description:
      - The resource name of the Feature Online Store.
      - This value may be up to 60 characters, and valid characters are [a-z0-9_].
      - The first character cannot be a number.
    required: true
    type: str
  optimized:
    description:
      - Settings for the Optimized store that will be created to serve featureValues for all FeatureViews under this FeatureOnlineStore.
    type: dict
  region:
    description:
      - The region of feature online store.
      - eg us-central1.
    type: str
  state:
    choices:
      - present
      - absent
    default: present
    description:
      - Whether the resource should exist in GCP.
    type: str
requirements:
  - python >= 3.8
  - requests >= 2.18.4
  - google-auth >= 2.25.1
short_description: Creates a GCP VertexAI.FeatureOnlineStore resource
"""

EXAMPLES = r"""
- name: Create Feature Online Store
  google.cloud.gcp_vertexai_feature_online_store:
    state: present
    name: my_feature_online_store
    bigtable:
      auto_scaling:
        min_node_count: 1
        max_node_count: 3
        cpu_utilization_target: 50
    region: us-central1
    project: "{{ gcp_project }}"
    auth_kind: "{{ gcp_cred_kind }}"
    service_account_file: "{{ gcp_cred_file }}"
"""

RETURN = r"""
changed:
  description: Whether the resource was changed.
  returned: always
  type: bool
createTime:
  description:
    - >-
      The timestamp of when the feature online store was created in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine

      fractional digits.
  returned: success
  type: str
etag:
  description:
    - Used to perform consistent read-modify-write updates.
  returned: success
  type: str
state:
  description:
    - The state of the Feature Online Store.
    - >-
      See the possible states in [this

      link](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.featureOnlineStores#state).
  returned: success
  type: str
updateTime:
  description:
    - >-
      The timestamp of when the feature online store was last updated in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine

      fractional digits.
  returned: success
  type: str
"""

################################################################################
# Imports
################################################################################

from ansible_collections.google.cloud.plugins.module_utils import gcp_utils as gcp
import types

# BEGIN Custom imports

# END Custom imports


def build_link(module_params, uri):
    params = module_params.copy()

    return ("https://{region}-aiplatform.googleapis.com/v1/" + uri).format(**params)


class Bigtable(gcp.Resource):
    def _request(self):
        return {
            "autoScaling": gcp.remove_empties(
                BigtableAutoScaling(self.request.get("auto_scaling", {})).to_request()
            ),  # remove empty values
            "enableDirectBigtableAccess": self.request.get("enable_direct_bigtable_access"),
            "zone": self.request.get("zone"),
        }

    def _response(self):
        return {
            "autoScaling": BigtableAutoScaling().from_response(self.response.get("autoScaling", {})),
            "enableDirectBigtableAccess": self.response.get("enableDirectBigtableAccess"),
            "zone": self.response.get("zone"),
        }


class BigtableAutoScaling(gcp.Resource):
    def _request(self):
        return {
            "cpuUtilizationTarget": self.request.get("cpu_utilization_target"),
            "maxNodeCount": self.request.get("max_node_count"),
            "minNodeCount": self.request.get("min_node_count"),
        }

    def _response(self):
        return {
            "cpuUtilizationTarget": self.response.get("cpuUtilizationTarget"),
            "maxNodeCount": self.response.get("maxNodeCount"),
            "minNodeCount": self.response.get("minNodeCount"),
        }


class DedicatedServingEndpoint(gcp.Resource):
    def _request(self):
        return {
            "privateServiceConnectConfig": gcp.remove_empties(
                DedicatedServingEndpointPrivateServiceConnectConfig(
                    self.request.get("private_service_connect_config", {})
                ).to_request()
            ),  # remove empty values
        }

    def _response(self):
        return {
            "privateServiceConnectConfig": DedicatedServingEndpointPrivateServiceConnectConfig().from_response(
                self.response.get("privateServiceConnectConfig", {})
            ),
            "publicEndpointDomainName": self.response.get("publicEndpointDomainName"),
            "serviceAttachment": self.response.get("serviceAttachment"),
        }


class DedicatedServingEndpointPrivateServiceConnectConfig(gcp.Resource):
    def _request(self):
        return {
            "enablePrivateServiceConnect": self.request.get("enable_private_service_connect"),
            "projectAllowlist": self.request.get("project_allowlist"),
        }

    def _response(self):
        return {
            "enablePrivateServiceConnect": self.response.get("enablePrivateServiceConnect"),
            "projectAllowlist": self.response.get("projectAllowlist"),
        }


class EmbeddingManagement(gcp.Resource):
    def _request(self):
        return {
            "enabled": self.request.get("enabled"),
        }

    def _response(self):
        return {
            "enabled": self.response.get("enabled"),
        }


class EncryptionSpec(gcp.Resource):
    def _request(self):
        return {
            "kmsKeyName": self.request.get("kms_key_name"),
        }

    def _response(self):
        return {
            "kmsKeyName": self.response.get("kmsKeyName"),
        }


class Optimized(gcp.Resource):
    def _request(self):
        return self.request.get("optimized", dict())

    def _response(self):
        return self.response.get("optimized", dict())


class VertexAI(gcp.Resource):
    def _request(self):
        return {
            "bigtable": gcp.remove_empties(
                Bigtable(self.request.get("bigtable", {})).to_request()
            ),  # remove empty values
            "dedicatedServingEndpoint": gcp.remove_empties(
                DedicatedServingEndpoint(self.request.get("dedicated_serving_endpoint", {})).to_request()
            ),  # remove empty values
            "embeddingManagement": gcp.remove_empties(
                EmbeddingManagement(self.request.get("embedding_management", {})).to_request()
            ),  # remove empty values
            "encryptionSpec": gcp.remove_empties(
                EncryptionSpec(self.request.get("encryption_spec", {})).to_request()
            ),  # remove empty values
            "labels": self.request.get("labels"),
            "optimized": gcp.remove_nones(
                Optimized(self.request.get("optimized", {})).to_request()
            ),  # allow empty values
        }

    def _response(self):
        return {
            "bigtable": Bigtable().from_response(self.response.get("bigtable", {})),
            "createTime": self.response.get("createTime"),
            "dedicatedServingEndpoint": DedicatedServingEndpoint().from_response(
                self.response.get("dedicatedServingEndpoint", {})
            ),
            "embeddingManagement": EmbeddingManagement().from_response(self.response.get("embeddingManagement", {})),
            "encryptionSpec": EncryptionSpec().from_response(self.response.get("encryptionSpec", {})),
            "etag": self.response.get("etag"),
            "labels": self.response.get("labels"),
            "optimized": Optimized().from_response(self.response.get("optimized", {})),
            "updateTime": self.response.get("updateTime"),
        }


################################################################################
# Main
################################################################################


def encode(self, obj):
    """
    This is a function bound to the main resource object. Its input is the object returned from to_request()
    and it mutates it before it is sent to the API.
    """
    return obj


def decode(self, obj):
    """
    This is a function bound to the main resource object. Its input is the object returned from from_response()
    and it mutates it before it is returned to the module caller.
    """
    return obj


def main():
    """Main function"""

    module = gcp.Module(
        argument_spec=dict(
            name=dict(
                type="str",
                required=True,
            ),
            state=dict(
                type="str",
                default="present",
                choices=["present", "absent"],
            ),
            bigtable=dict(
                type="dict",
                options=dict(
                    auto_scaling=dict(
                        type="dict",
                        required=True,
                        options=dict(
                            cpu_utilization_target=dict(
                                type="int",
                            ),
                            max_node_count=dict(
                                type="int",
                                required=True,
                            ),
                            min_node_count=dict(
                                type="int",
                                required=True,
                            ),
                        ),
                    ),
                    enable_direct_bigtable_access=dict(
                        type="bool",
                    ),
                    zone=dict(
                        type="str",
                    ),
                ),
            ),
            dedicated_serving_endpoint=dict(
                type="dict",
                options=dict(
                    private_service_connect_config=dict(
                        type="dict",
                        options=dict(
                            enable_private_service_connect=dict(
                                type="bool",
                                required=True,
                            ),
                            project_allowlist=dict(
                                type="list",
                                elements="str",
                            ),
                        ),
                    ),
                    public_endpoint_domain_name=dict(
                        type="str",
                    ),
                    service_attachment=dict(
                        type="str",
                    ),
                ),
            ),
            embedding_management=dict(
                type="dict",
                options=dict(
                    enabled=dict(
                        type="bool",
                    )
                ),
            ),
            encryption_spec=dict(
                type="dict",
                options=dict(
                    kms_key_name=dict(
                        type="str",
                        required=True,
                        no_log=False,
                    )
                ),
            ),
            force_destroy=dict(
                type="bool",
                default=False,
            ),
            labels=dict(
                type="dict",
            ),
            optimized=dict(
                type="dict",
            ),
            region=dict(
                type="str",
            ),
        ),
        mutually_exclusive=[["bigtable", "optimized"], ["embedding_management", "optimized"]],
        required_one_of=[["bigtable", "optimized"]],
    )

    if not module.params["scopes"]:
        module.params["scopes"] = ["https://www.googleapis.com/auth/cloud-platform"]

    state = module.params["state"]
    changed = False
    op_configs = gcp.ResourceOpConfigs(
        {
            "base_url": gcp.ResourceOpConfig(
                **{
                    "uri": "projects/{project}/locations/{region}/featureOnlineStores",
                    "async_uri": "",
                    "verb": "GET",
                    "timeout_minutes": 0,
                }
            ),
            "create": gcp.ResourceOpConfig(
                **{
                    "uri": "projects/{project}/locations/{region}/featureOnlineStores?featureOnlineStoreId={name}",
                    "async_uri": "{op_id}",
                    "verb": "POST",
                    "timeout_minutes": 20,
                }
            ),
            "delete": gcp.ResourceOpConfig(
                **{
                    "uri": "projects/{project}/locations/{region}/featureOnlineStores/{name}",
                    "async_uri": "{op_id}",
                    "verb": "DELETE",
                    "timeout_minutes": 20,
                }
            ),
            "read": gcp.ResourceOpConfig(
                **{
                    "uri": "projects/{project}/locations/{region}/featureOnlineStores/{name}",
                    "async_uri": "",
                    "verb": "GET",
                    "timeout_minutes": 0,
                }
            ),
            "update": gcp.ResourceOpConfig(
                **{
                    "uri": "projects/{project}/locations/{region}/featureOnlineStores/{name}",
                    "async_uri": "{op_id}",
                    "verb": "PATCH",
                    "timeout_minutes": 20,
                }
            ),
        }
    )

    params = gcp.remove_nones(module.params)
    resource = VertexAI(params, module=module, product="VertexAI", kind="vertexai#featureOnlineStore")
    read_uri = op_configs.read.uri

    resource._state = state  # store the state in the resource object
    # Bind the encode and decode functions to the resource object
    resource.encode_func = types.MethodType(encode, resource)
    resource.decode_func = types.MethodType(decode, resource)

    custom_diff = None  # Set this variable if you want to implement custom diff logic

    read_url = build_link(params, read_uri)
    existing_obj = resource.get(read_url, allow_not_found=True) or {}
    new_obj = {}
    gcp.debug(module, existing=existing_obj, post=False)

    if custom_diff is not None:
        is_different = custom_diff
    else:
        is_different = resource.diff(gcp.remove_empties(existing_obj))
    gcp.debug(
        module,
        request=gcp.remove_empties(resource.to_request()),
        existing=existing_obj,
        post=True,
        is_different=is_different,
    )

    if gcp.empty(existing_obj):
        if state == "present":
            create_uri = op_configs.create.uri
            create_async_uri = op_configs.create.async_uri
            try:
                # --------- BEGIN create code ---------
                is_async = create_async_uri != ""
                create_link = build_link(params, create_uri)
                create_retries = op_configs.create.timeout
                create_func = getattr(resource, op_configs.create.verb)
                async_create_func = getattr(resource, op_configs.create.verb + "_async")
                async_create_link = build_link(params, "") + create_async_uri
                gcp.debug(
                    module,
                    msg="Creating resource",
                    create_link=create_link,
                    async_create_link=async_create_link,
                    is_async=is_async,
                )

                if is_async:
                    new_obj = async_create_func(create_link, async_link=async_create_link, retries=create_retries)
                else:
                    new_obj = create_func(create_link)
                gcp.debug(module, new=new_obj, action="create", post=False)
                gcp.debug(module, new=new_obj, action="create", post=True)
                # --------- END create code ---------
            except Exception as e:
                module.fail_json(msg=str(e))

            changed = True
        else:
            pass  # nothing to do
    else:
        if state == "absent":
            delete_uri = op_configs.delete.uri
            delete_async_uri = op_configs.delete.async_uri
            try:
                # --------- BEGIN delete code ---------
                # --------- BEGIN pre-delete custom code ---------
                if params.get("force_destroy"):
                    delete_uri += "?force=true"
                # --------- END pre-delete custom code ---------
                is_async = delete_async_uri != ""
                delete_link = build_link(params, delete_uri)
                delete_retries = op_configs.delete.timeout
                delete_func = getattr(resource, op_configs.delete.verb)
                async_delete_func = getattr(resource, op_configs.delete.verb + "_async")
                async_delete_link = build_link(params, "") + delete_async_uri
                gcp.debug(
                    module,
                    msg="Destroying resource",
                    delete_link=delete_link,
                    async_delete_link=async_delete_link,
                    is_async=is_async,
                )
                if is_async:
                    new_obj = async_delete_func(delete_link, async_link=async_delete_link, retries=delete_retries)
                else:
                    new_obj = delete_func(delete_link)
                # --------- END delete code ---------
            except Exception as e:
                module.fail_json(msg=str(e))

            changed = True
        else:
            if is_different:
                update_uri = op_configs.update.uri
                update_async_uri = op_configs.update.async_uri
                try:
                    # --------- BEGIN update code ---------
                    is_async = update_async_uri != ""
                    update_link = build_link(params, update_uri)
                    update_retries = op_configs.update.timeout
                    update_func = getattr(resource, op_configs.update.verb)
                    async_update_func = getattr(resource, op_configs.update.verb + "_async")
                    async_update_link = build_link(params, "") + update_async_uri
                    gcp.debug(
                        module,
                        msg="Updating resource",
                        update_link=update_link,
                        async_update_link=async_update_link,
                        is_async=is_async,
                    )
                    if is_async:
                        new_obj = async_update_func(update_link, async_link=async_update_link, retries=update_retries)
                    else:
                        new_obj = update_func(update_link)
                    gcp.debug(module, new=new_obj, action="update", post=False)
                    gcp.debug(module, new=new_obj, action="update", post=True)
                    # --------- END update code ---------
                except Exception as e:
                    module.fail_json(msg=str(e))

                changed = True
            else:
                new_obj = existing_obj

    new_obj.update({"changed": changed})
    module.exit_json(**new_obj)


if __name__ == "__main__":
    main()
