#!/usr/bin/python
# -*- coding: utf-8 -*-
#
# Copyright (C) 2017-2026 Google
# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)
# ----------------------------------------------------------------------------
#
#     ***     AUTO GENERATED CODE    ***    Type: MMv1     ***
#
# ----------------------------------------------------------------------------
#
#     This file is automatically generated by Magic Modules and manual
#     changes will be clobbered when the file is regenerated.
#
# ----------------------------------------------------------------------------
#

from __future__ import absolute_import, division, print_function

__metaclass__ = type

################################################################################
# Documentation
################################################################################

ANSIBLE_METADATA = {
    "metadata_version": "1.1",
    "status": ["preview"],
    "supported_by": "community",
}

DOCUMENTATION = r"""
---
author:
  - Google Inc. (@googlecloudplatform)
description:
  - An entity type is a type of object in a system that needs to be modeled and have stored information about. For example, driver is an entity type, and driver0 is an instance of an entity type driver.
extends_documentation_fragment:
  - google.cloud.gcp
module: gcp_vertexai_featurestore_entitytype
notes:
  - 'API Reference: U(https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.featurestores.entityTypes)'
  - 'Official Documentation Guide: U(https://cloud.google.com/vertex-ai/docs)'
options:
  description:
    description:
      - Description of the EntityType.
    type: str
  featurestore:
    description:
      - The name of the Featurestore to use, in the format projects/{project}/locations/{location}/featurestores/{featurestore}.
    required: true
    type: str
  labels:
    description:
      - A set of key/value label pairs to assign to this EntityType.
    type: dict
  monitoring_config:
    description:
      - The default monitoring configuration for all Features under this EntityType.
      - If this is populated with [FeaturestoreMonitoringConfig.monitoring_interval] specified, snapshot analysis monitoring is enabled.
      - Otherwise, snapshot analysis monitoring is disabled.
    suboptions:
      categorical_threshold_config:
        description:
          - Threshold for categorical features of anomaly detection.
          - This is shared by all types of Featurestore Monitoring for categorical features (i.e.
          - Features with type (Feature.ValueType) BOOL or STRING).
        suboptions:
          value:
            description:
              - Specify a threshold value that can trigger the alert.
              - For categorical feature, the distribution distance is calculated by L-inifinity norm.
              - Each feature must have a non-zero threshold if they need to be monitored.
              - Otherwise no alert will be triggered for that feature.
              - The default value is 0.3.
            required: true
            type: str
        type: dict
      import_features_analysis:
        description:
          - The config for ImportFeatures Analysis Based Feature Monitoring.
        suboptions:
          anomaly_detection_baseline:
            description:
              - Defines the baseline to do anomaly detection for feature values imported by each [entityTypes.importFeatureValues][] operation.
              - 'The value must be one of the values below: * LATEST_STATS: Choose the later one statistics generated by either most recent snapshot analysis or previous import features analysis.'
              - If non of them exists, skip anomaly detection and only generate a statistics.
              - '* MOST_RECENT_SNAPSHOT_STATS: Use the statistics generated by the most recent snapshot analysis if exists.'
              - '* PREVIOUS_IMPORT_FEATURES_STATS: Use the statistics generated by the previous import features analysis if exists.'
            type: str
          state:
            description:
              - Whether to enable / disable / inherite default hebavior for import features analysis.
              - 'The value must be one of the values below: * DEFAULT: The default behavior of whether to enable the monitoring.'
              - 'EntityType-level config: disabled.'
              - '* ENABLED: Explicitly enables import features analysis.'
              - 'EntityType-level config: by default enables import features analysis for all Features under it.'
              - '* DISABLED: Explicitly disables import features analysis.'
              - 'EntityType-level config: by default disables import features analysis for all Features under it.'
            type: str
        type: dict
      numerical_threshold_config:
        description:
          - Threshold for numerical features of anomaly detection.
          - This is shared by all objectives of Featurestore Monitoring for numerical features (i.e.
          - Features with type (Feature.ValueType) DOUBLE or INT64).
        suboptions:
          value:
            description:
              - Specify a threshold value that can trigger the alert.
              - For numerical feature, the distribution distance is calculated by Jensenâ€“Shannon divergence.
              - Each feature must have a non-zero threshold if they need to be monitored.
              - Otherwise no alert will be triggered for that feature.
              - The default value is 0.3.
            required: true
            type: str
        type: dict
      snapshot_analysis:
        description:
          - The config for Snapshot Analysis Based Feature Monitoring.
        suboptions:
          disabled:
            default: false
            description:
              - The monitoring schedule for snapshot analysis.
              - 'For EntityType-level config: unset / disabled = true indicates disabled by default for Features under it; otherwise by default enable snapshot analysis monitoring with monitoringInterval for Features under it.'
            type: bool
          monitoring_interval:
            description:
              - Configuration of the snapshot analysis based monitoring pipeline running interval.
              - The value is rolled up to full day.
              - A duration in seconds with up to nine fractional digits, terminated by 's'.
              - 'Example: "3.5s".'
            type: str
          monitoring_interval_days:
            default: 1
            description:
              - Configuration of the snapshot analysis based monitoring pipeline running interval.
              - The value indicates number of days.
              - The default value is 1.
              - If both FeaturestoreMonitoringConfig.SnapshotAnalysis.monitoring_interval_days and [FeaturestoreMonitoringConfig.SnapshotAnalysis.monitoring_interval][] are set when creating/updating EntityTypes/Features, FeaturestoreMonitoringConfig.SnapshotAnalysis.monitoring_interval_days will be used.
            type: int
          staleness_days:
            default: 21
            description:
              - Customized export features time window for snapshot analysis.
              - Unit is one day.
              - The default value is 21 days.
              - Minimum value is 1 day.
              - Maximum value is 4000 days.
            type: int
        type: dict
    type: dict
  name:
    description:
      - The name of the EntityType.
      - This value may be up to 60 characters, and valid characters are [a-z0-9_].
      - The first character cannot be a number.
    required: true
    type: str
  offline_storage_ttl_days:
    default: 4000
    description:
      - Config for data retention policy in offline storage.
      - TTL in days for feature values that will be stored in offline storage.
      - The Feature Store offline storage periodically removes obsolete feature values older than offlineStorageTtlDays since the feature generation time.
      - If unset (or explicitly set to 0), default to 4000 days TTL.
    type: int
  state:
    choices:
      - present
      - absent
    default: present
    description:
      - Whether the resource should exist in GCP.
    type: str
requirements:
  - python >= 3.8
  - requests >= 2.18.4
  - google-auth >= 2.25.1
short_description: Creates a GCP VertexAI.FeaturestoreEntitytype resource
"""  # noqa: E501

EXAMPLES = r"""
- name: Create Featurestore Entitytype
  google.cloud.gcp_vertexai_featurestore_entitytype:
    state: present
    name: my_featurestore_entitytype
    featurestore: "projects/{{ gcp_project }}/locations/{{ gcp_region }}/featurestores/{{ featurestore }}"
    # featurestore: "{{ _myfs.name }}"  # use previously registered variable
    monitoring_config:
      snapshot_analysis:
        disabled: false
        monitoring_interval_days: 1
        staleness_days: 30
    project: "{{ gcp_project }}"
    auth_kind: "{{ gcp_cred_kind }}"
    service_account_file: "{{ gcp_cred_file }}"
"""  # noqa: E501

RETURN = r"""
changed:
  description: Whether the resource was changed.
  returned: always
  type: bool
createTime:
  description:
    - The timestamp of when the featurestore was created in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine fractional digits.
  returned: success
  type: str
etag:
  description:
    - Used to perform consistent read-modify-write updates.
  returned: success
  type: str
state:
  description: The current state of the resource.
  returned: always
  type: str
updateTime:
  description:
    - The timestamp of when the featurestore was last updated in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine fractional digits.
  returned: success
  type: str
"""  # noqa: E501

################################################################################
# Imports
################################################################################

from ansible_collections.google.cloud.plugins.module_utils import gcp_utils as gcp
import types

# BEGIN Custom imports
import re

# END Custom imports


def build_link(module_params, uri):
    params = module_params.copy()

    return ("https://{region}-aiplatform.googleapis.com/v1/" + uri).format(**params)


class MonitoringConfig(gcp.Resource):
    def _request(self):
        return {
            "categoricalThresholdConfig": gcp.remove_empties(
                MonitoringConfigCategoricalThresholdConfig(
                    self.request.get("categorical_threshold_config", {})
                ).to_request()
            ),  # remove empty values
            "importFeaturesAnalysis": gcp.remove_empties(
                MonitoringConfigImportFeaturesAnalysis(self.request.get("import_features_analysis", {})).to_request()
            ),  # remove empty values
            "numericalThresholdConfig": gcp.remove_empties(
                MonitoringConfigNumericalThresholdConfig(
                    self.request.get("numerical_threshold_config", {})
                ).to_request()
            ),  # remove empty values
            "snapshotAnalysis": gcp.remove_empties(
                MonitoringConfigSnapshotAnalysis(self.request.get("snapshot_analysis", {})).to_request()
            ),  # remove empty values
        }

    def _response(self):
        return {
            "categoricalThresholdConfig": MonitoringConfigCategoricalThresholdConfig().from_response(
                self.response.get("categoricalThresholdConfig", {})
            ),
            "importFeaturesAnalysis": MonitoringConfigImportFeaturesAnalysis().from_response(
                self.response.get("importFeaturesAnalysis", {})
            ),
            "numericalThresholdConfig": MonitoringConfigNumericalThresholdConfig().from_response(
                self.response.get("numericalThresholdConfig", {})
            ),
            "snapshotAnalysis": MonitoringConfigSnapshotAnalysis().from_response(
                self.response.get("snapshotAnalysis", {})
            ),
        }


class MonitoringConfigCategoricalThresholdConfig(gcp.Resource):
    def _request(self):
        return {
            "value": self.request.get("value"),
        }

    def _response(self):
        return {
            "value": self.response.get("value"),
        }


class MonitoringConfigImportFeaturesAnalysis(gcp.Resource):
    def _request(self):
        return {
            "anomalyDetectionBaseline": self.request.get("anomaly_detection_baseline"),
            "state": self.request.get("state"),
        }

    def _response(self):
        return {
            "anomalyDetectionBaseline": self.response.get("anomalyDetectionBaseline"),
            "state": self.response.get("state"),
        }


class MonitoringConfigNumericalThresholdConfig(gcp.Resource):
    def _request(self):
        return {
            "value": self.request.get("value"),
        }

    def _response(self):
        return {
            "value": self.response.get("value"),
        }


class MonitoringConfigSnapshotAnalysis(gcp.Resource):
    def _request(self):
        return {
            "disabled": self.request.get("disabled"),
            "monitoringInterval": self.request.get("monitoring_interval"),
            "monitoringIntervalDays": self.request.get("monitoring_interval_days"),
            "stalenessDays": self.request.get("staleness_days"),
        }

    def _response(self):
        return {
            "disabled": self.response.get("disabled"),
            "monitoringInterval": self.response.get("monitoringInterval"),
            "monitoringIntervalDays": self.response.get("monitoringIntervalDays"),
            "stalenessDays": self.response.get("stalenessDays"),
        }


class VertexAI(gcp.Resource):
    def _request(self):
        return {
            "description": self.request.get("description"),
            "labels": self.request.get("labels"),
            "monitoringConfig": gcp.remove_empties(
                MonitoringConfig(self.request.get("monitoring_config", {})).to_request()
            ),  # remove empty values
            "offlineStorageTtlDays": self.request.get("offline_storage_ttl_days"),
        }

    def _response(self):
        return {
            "createTime": self.response.get("createTime"),
            "description": self.response.get("description"),
            "etag": self.response.get("etag"),
            "labels": self.response.get("labels"),
            "monitoringConfig": MonitoringConfig().from_response(self.response.get("monitoringConfig", {})),
            "offlineStorageTtlDays": self.response.get("offlineStorageTtlDays"),
            "updateTime": self.response.get("updateTime"),
        }


################################################################################
# Main
################################################################################


def encode(self, obj):
    """
    This is a function bound to the main resource object. Its input is the object returned from to_request()
    and it mutates it before it is sent to the API.
    """
    return obj


def decode(self, obj):
    """
    This is a function bound to the main resource object. Its input is the object returned from from_response()
    and it mutates it before it is returned to the module caller.
    """
    return obj


def main():
    """Main function"""

    module = gcp.Module(
        argument_spec=dict(
            name=dict(
                type="str",
                required=True,
            ),
            state=dict(
                type="str",
                default="present",
                choices=["present", "absent"],
            ),
            description=dict(
                type="str",
            ),
            featurestore=dict(
                type="str",
                required=True,
            ),
            labels=dict(
                type="dict",
            ),
            monitoring_config=dict(
                type="dict",
                options=dict(
                    categorical_threshold_config=dict(
                        type="dict",
                        options=dict(
                            value=dict(
                                type="str",
                                required=True,
                            )
                        ),
                    ),
                    import_features_analysis=dict(
                        type="dict",
                        options=dict(
                            anomaly_detection_baseline=dict(
                                type="str",
                            ),
                            state=dict(
                                type="str",
                            ),
                        ),
                    ),
                    numerical_threshold_config=dict(
                        type="dict",
                        options=dict(
                            value=dict(
                                type="str",
                                required=True,
                            )
                        ),
                    ),
                    snapshot_analysis=dict(
                        type="dict",
                        options=dict(
                            disabled=dict(
                                type="bool",
                                default=False,
                            ),
                            monitoring_interval=dict(
                                type="str",
                            ),
                            monitoring_interval_days=dict(
                                type="int",
                                default=1,
                            ),
                            staleness_days=dict(
                                type="int",
                                default=21,
                            ),
                        ),
                    ),
                ),
            ),
            offline_storage_ttl_days=dict(
                type="int",
                default=4000,
            ),
        )
    )

    if not module.params["scopes"]:
        module.params["scopes"] = ["https://www.googleapis.com/auth/cloud-platform"]

    state = module.params["state"]
    changed = False
    op_configs = gcp.ResourceOpConfigs(
        {
            "base_url": gcp.ResourceOpConfig(
                **{"uri": "{featurestore}/entityTypes", "async_uri": "", "verb": "GET", "timeout_minutes": 0}
            ),
            "create": gcp.ResourceOpConfig(
                **{
                    "uri": "{featurestore}/entityTypes?entityTypeId={name}",
                    "async_uri": "{op_id}",
                    "verb": "POST",
                    "timeout_minutes": 20,
                }
            ),
            "delete": gcp.ResourceOpConfig(
                **{
                    "uri": "{featurestore}/entityTypes/{name}",
                    "async_uri": "{op_id}",
                    "verb": "DELETE",
                    "timeout_minutes": 20,
                }
            ),
            "read": gcp.ResourceOpConfig(
                **{"uri": "{featurestore}/entityTypes/{name}", "async_uri": "", "verb": "GET", "timeout_minutes": 0}
            ),
            "update": gcp.ResourceOpConfig(
                **{"uri": "{featurestore}/entityTypes/{name}", "async_uri": "", "verb": "PATCH", "timeout_minutes": 20}
            ),
        }
    )

    params = gcp.remove_nones(module.params)
    resource = VertexAI(params, module=module, product="VertexAI", kind="vertexai#featurestoreEntitytype")
    read_uri = op_configs.read.uri

    resource._state = state  # store the state in the resource object
    # Bind the encode and decode functions to the resource object
    resource.encode_func = types.MethodType(encode, resource)
    resource.decode_func = types.MethodType(decode, resource)

    custom_diff = None  # Set this variable if you want to implement custom diff logic

    # --------- BEGIN pre-read custom code ---------
    # if this comes from a registered variable, strip down to base name
    params["name"] = params["name"].split("/")[-1]

    # extract region from featurestore
    pattern = r"projects/(.+)/locations/(.+)/featurestores/(.+)"
    match = re.search(pattern, str(params["featurestore"]))
    if match:
        params["region"] = match.group(2)

    # --------- END pre-read custom code ---------

    read_url = build_link(params, read_uri)
    existing_obj = resource.get(read_url, allow_not_found=True) or {}
    new_obj = {}
    gcp.debug(module, existing=existing_obj, post=False)

    if custom_diff is not None:
        is_different = custom_diff
    else:
        is_different = resource.diff(gcp.remove_empties(existing_obj))
    gcp.debug(
        module,
        request=gcp.remove_empties(resource.to_request()),
        existing=existing_obj,
        post=True,
        is_different=is_different,
    )

    if gcp.empty(existing_obj):
        if state == "present":
            create_uri = op_configs.create.uri
            create_async_uri = op_configs.create.async_uri
            try:
                # --------- BEGIN create code ---------
                is_async = create_async_uri != ""
                create_link = build_link(params, create_uri)
                create_retries = op_configs.create.timeout
                create_func = getattr(resource, op_configs.create.verb)
                async_create_func = getattr(resource, op_configs.create.verb + "_async")
                async_create_link = build_link(params, "") + create_async_uri
                gcp.debug(
                    module,
                    msg="Creating resource",
                    create_link=create_link,
                    async_create_link=async_create_link,
                    is_async=is_async,
                )

                if is_async:
                    new_obj = async_create_func(create_link, async_link=async_create_link, retries=create_retries)
                else:
                    new_obj = create_func(create_link)
                gcp.debug(module, new=new_obj, action="create", post=False)
                gcp.debug(module, new=new_obj, action="create", post=True)
                # --------- END create code ---------
            except Exception as e:
                module.fail_json(msg=str(e))

            changed = True
        else:
            pass  # nothing to do
    else:
        if state == "absent":
            delete_uri = op_configs.delete.uri
            delete_async_uri = op_configs.delete.async_uri
            try:
                # --------- BEGIN delete code ---------
                is_async = delete_async_uri != ""
                delete_link = build_link(params, delete_uri)
                delete_retries = op_configs.delete.timeout
                delete_func = getattr(resource, op_configs.delete.verb)
                async_delete_func = getattr(resource, op_configs.delete.verb + "_async")
                async_delete_link = build_link(params, "") + delete_async_uri
                gcp.debug(
                    module,
                    msg="Destroying resource",
                    delete_link=delete_link,
                    async_delete_link=async_delete_link,
                    is_async=is_async,
                )
                if is_async:
                    new_obj = async_delete_func(delete_link, async_link=async_delete_link, retries=delete_retries)
                else:
                    new_obj = delete_func(delete_link)
                # --------- END delete code ---------
            except Exception as e:
                module.fail_json(msg=str(e))

            changed = True
        else:
            if is_different:
                update_uri = op_configs.update.uri
                update_async_uri = op_configs.update.async_uri
                try:
                    # --------- BEGIN update code ---------
                    is_async = update_async_uri != ""
                    update_link = build_link(params, update_uri)
                    update_retries = op_configs.update.timeout
                    update_func = getattr(resource, op_configs.update.verb)
                    async_update_func = getattr(resource, op_configs.update.verb + "_async")
                    async_update_link = build_link(params, "") + update_async_uri
                    gcp.debug(
                        module,
                        msg="Updating resource",
                        update_link=update_link,
                        async_update_link=async_update_link,
                        is_async=is_async,
                    )
                    if is_async:
                        new_obj = async_update_func(update_link, async_link=async_update_link, retries=update_retries)
                    else:
                        new_obj = update_func(update_link)
                    gcp.debug(module, new=new_obj, action="update", post=False)
                    gcp.debug(module, new=new_obj, action="update", post=True)
                    # --------- END update code ---------
                except Exception as e:
                    module.fail_json(msg=str(e))

                changed = True
            else:
                new_obj = existing_obj

    new_obj.update({"changed": changed})
    module.exit_json(**new_obj)


if __name__ == "__main__":
    main()
