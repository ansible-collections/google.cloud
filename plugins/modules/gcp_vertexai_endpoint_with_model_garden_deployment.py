#!/usr/bin/python
# -*- coding: utf-8 -*-
#
# Copyright (C) 2017-2026 Google
# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)
# ----------------------------------------------------------------------------
#
#     ***     AUTO GENERATED CODE    ***    Type: MMv1     ***
#
# ----------------------------------------------------------------------------
#
#     This file is automatically generated by Magic Modules and manual
#     changes will be clobbered when the file is regenerated.
#
# ----------------------------------------------------------------------------
#

from __future__ import absolute_import, division, print_function

__metaclass__ = type

################################################################################
# Documentation
################################################################################

ANSIBLE_METADATA = {
    "metadata_version": "1.1",
    "status": ["preview"],
    "supported_by": "community",
}

DOCUMENTATION = r"""
---
author:
  - Google Inc. (@googlecloudplatform)
description:
  - Create an Endpoint and deploy a Model Garden model to it.
extends_documentation_fragment:
  - google.cloud.gcp
module: gcp_vertexai_endpoint_with_model_garden_deployment
notes:
  - 'API Reference: U(https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations/deploy)'
  - 'Use models in Model Garden Guide: U(https://cloud.google.com/vertex-ai/generative-ai/docs/model-garden/use-models)'
  - 'Overview of Model Garden Guide: U(https://cloud.google.com/vertex-ai/generative-ai/docs/model-garden/explore-models)'
  - 'Overview of self-deployed models Guide: U(https://cloud.google.com/vertex-ai/generative-ai/docs/model-garden/self-deployed-models)'
options:
  deploy_config:
    description:
      - The deploy config to use for the deployment.
    suboptions:
      dedicated_resources:
        description:
          - A description of resources that are dedicated to a DeployedModel or DeployedIndex, and that need a higher degree of manual configuration.
        suboptions:
          autoscaling_metric_specs:
            description:
              - >-
                The metric specifications that overrides a resource utilization metric (CPU utilization, accelerator's duty cycle, and so on) target value

                (default to 60 if not set).
              - At most one entry is allowed per metric.
              - >-
                If machine_spec.accelerator_count is above 0, the autoscaling will be based on both CPU utilization and accelerator's duty cycle metrics and

                scale up when either metrics exceeds its target value while scale down if both metrics are under their target value.
              - The default target value is 60 for both metrics.
              - >-
                If machine_spec.accelerator_count is 0, the autoscaling will be based on CPU utilization metric only with default target value 60 if not

                explicitly set.
              - >-
                For example, in the case of Online Prediction, if you want to override target CPU utilization to 80, you should set

                autoscaling_metric_specs.metric_name to `aiplatform.googleapis.com/prediction/online/cpu/utilization` and autoscaling_metric_specs.target to

                `80`.
            elements: dict
            suboptions:
              metric_name:
                description:
                  - The resource metric name.
                  - >-
                    Supported metrics: * For Online Prediction: * `aiplatform.googleapis.com/prediction/online/accelerator/duty_cycle` *

                    `aiplatform.googleapis.com/prediction/online/cpu/utilization`.
                required: true
                type: str
              target:
                description:
                  - >-
                    The target resource utilization in percentage (1% - 100%) for the given metric; once the real usage deviates from the target by a certain

                    percentage, the machine replicas change.
                  - The default value is 60 (representing 60%) if not provided.
                type: int
            type: list
          machine_spec:
            description:
              - Specification of a single machine.
            required: true
            suboptions:
              accelerator_count:
                description:
                  - The number of accelerators to attach to the machine.
                type: int
              accelerator_type:
                description:
                  - >-
                    Possible values: ACCELERATOR_TYPE_UNSPECIFIED NVIDIA_TESLA_K80 NVIDIA_TESLA_P100 NVIDIA_TESLA_V100 NVIDIA_TESLA_P4 NVIDIA_TESLA_T4

                    NVIDIA_TESLA_A100 NVIDIA_A100_80GB NVIDIA_L4 NVIDIA_H100_80GB NVIDIA_H100_MEGA_80GB NVIDIA_H200_141GB NVIDIA_B200 TPU_V2 TPU_V3 TPU_V4_POD

                    TPU_V5_LITEPOD.
                type: str
              machine_type:
                description:
                  - The type of the machine.
                  - >-
                    See the [list of machine types supported for

                    prediction](https://cloud.google.com/vertex-ai/docs/predictions/configure-compute#machine-types) See the [list of machine types supported

                    for custom training](https://cloud.google.com/vertex-ai/docs/training/configure-compute#machine-types).
                  - For DeployedModel this field is optional, and the default value is `n1-standard-2`.
                  - For BatchPredictionJob or as part of WorkerPoolSpec this field is required.
                type: str
              multihost_gpu_node_count:
                description:
                  - The number of nodes per replica for multihost GPU deployments.
                type: int
              reservation_affinity:
                description:
                  - >-
                    A ReservationAffinity can be used to configure a Vertex AI resource (e.g., a DeployedModel) to draw its Compute Engine resources from a

                    Shared Reservation, or exclusively from on-demand capacity.
                suboptions:
                  key:
                    description:
                      - Corresponds to the label key of a reservation resource.
                      - >-
                        To target a SPECIFIC_RESERVATION by name, use `compute.googleapis.com/reservation-name` as the key and specify the name of your reservation

                        as its value.
                    type: str
                  reservation_affinity_type:
                    description:
                      - Specifies the reservation affinity type.
                      - 'Possible values: TYPE_UNSPECIFIED NO_RESERVATION ANY_RESERVATION SPECIFIC_RESERVATION.'
                    required: true
                    type: str
                  values:
                    description:
                      - Corresponds to the label values of a reservation resource.
                      - This must be the full resource name of the reservation or reservation block.
                    elements: str
                    type: list
                type: dict
              tpu_topology:
                description:
                  - The topology of the TPUs.
                  - Corresponds to the TPU topologies available from GKE.
                  - '(Example: tpu_topology: "2x2x1").'
                type: str
            type: dict
          max_replica_count:
            description:
              - The maximum number of replicas that may be deployed on when the traffic against it increases.
              - >-
                If the requested value is too large, the deployment will error, but if deployment succeeds then the ability to scale to that many replicas

                is guaranteed (barring service outages).
              - If traffic increases beyond what its replicas at maximum may handle, a portion of the traffic will be dropped.
              - If this value is not provided, will use min_replica_count as the default value.
              - The value of this field impacts the charge against Vertex CPU and GPU quotas.
              - >-
                Specifically, you will be charged for (max_replica_count * number of cores in the selected machine type) and (max_replica_count * number of

                GPUs per replica in the selected machine type).
            type: int
          min_replica_count:
            description:
              - The minimum number of machine replicas that will be always deployed on.
              - This value must be greater than or equal to 1.
              - >-
                If traffic increases, it may dynamically be deployed onto more replicas, and as traffic decreases, some of these extra replicas may be

                freed.
            required: true
            type: int
          required_replica_count:
            description:
              - Number of required available replicas for the deployment to succeed.
              - This field is only needed when partial deployment/mutation is desired.
              - >-
                If set, the deploy/mutate operation will succeed once available_replica_count reaches required_replica_count, and the rest of the replicas

                will be retried.
              - If not set, the default required_replica_count will be min_replica_count.
            type: int
          spot:
            description:
              - If true, schedule the deployment workload on [spot VMs](https://cloud.google.com/kubernetes-engine/docs/concepts/spot-vms).
            type: bool
        type: dict
      fast_tryout_enabled:
        description:
          - If true, enable the QMT fast tryout feature for this model if possible.
        type: bool
      system_labels:
        description:
          - System labels for Model Garden deployments.
          - These labels are managed by Google and for tracking purposes only.
        type: dict
    type: dict
  display_name:
    description:
      - The user-specified display name.
      - This will be the default display name for both the endpoint and the deployed model.
    required: true
    type: str
  endpoint_config:
    description:
      - The endpoint config to use for the deployment.
    suboptions:
      dedicated_endpoint_enabled:
        description:
          - If true, the endpoint will be exposed through a dedicated DNS [Endpoint.dedicated_endpoint_dns].
          - Your request to the dedicated DNS will be isolated from other users' traffic and will have better performance and reliability.
          - 'Note: Once you enabled dedicated endpoint, you won''t be able to send request to the shared DNS {region}-aiplatform.googleapis.com.'
          - The limitations will be removed soon.
        type: bool
      endpoint_display_name:
        description:
          - The user-specified display name of the endpoint.
          - If not set, a default name will be used.
        type: str
      private_service_connect_config:
        description:
          - The configuration for Private Service Connect (PSC).
        suboptions:
          enable_private_service_connect:
            description:
              - If true, expose the IndexEndpoint via private service connect.
            required: true
            type: bool
          project_allowlist:
            description:
              - A list of Projects from which the forwarding rule will target the service attachment.
            elements: str
            type: list
          psc_automation_configs:
            description:
              - PSC config that is used to automatically create PSC endpoints in the user projects.
            suboptions:
              error_message:
                description:
                  - Output only.
                  - Error message if the PSC service automation failed.
                type: str
              forwarding_rule:
                description:
                  - Output only.
                  - Forwarding rule created by the PSC service automation.
                type: str
              ip_address:
                description:
                  - Output only.
                  - IP address rule created by the PSC service automation.
                type: str
              network:
                description:
                  - The full name of the Google Compute Engine network.
                  - 'Format: projects/{project}/global/networks/{network}.'
                required: true
                type: str
              project_id:
                description:
                  - Project id used to create forwarding rule.
                required: true
                type: str
              state:
                choices:
                  - PSC_AUTOMATION_STATE_UNSPECIFIED
                  - PSC_AUTOMATION_STATE_SUCCESSFUL
                  - PSC_AUTOMATION_STATE_FAILED
                description:
                  - Output only.
                  - The state of the PSC service automation.
                type: str
            type: dict
          service_attachment:
            description:
              - Output only.
              - The name of the generated service attachment resource.
              - This is only populated if the endpoint is deployed with PrivateServiceConnect.
            type: str
        type: dict
    type: dict
  hugging_face_model_id:
    description:
      - The Hugging Face model to deploy.
      - 'Format: Hugging Face model ID like `google/gemma-2-2b-it`.'
    type: str
  location:
    description:
      - Resource ID segment making up resource `location`.
      - It identifies the resource within its parent collection as described in https://google.aip.dev/122.
    required: true
    type: str
  model_config:
    description:
      - The model config to use for the deployment.
    suboptions:
      accept_eula:
        description:
          - Whether the user accepts the End User License Agreement (EULA) for the model.
        type: bool
      container_spec:
        description:
          - Specification of a container for serving predictions.
          - >-
            Some fields in this message correspond to fields in the [Kubernetes Container v1 core

            specification](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
        suboptions:
          args:
            description:
              - Specifies arguments for the command that runs when the container starts.
              - This overrides the container's [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd).
              - Specify this field as an array of executable and arguments, similar to a Docker `CMD`'s "default parameters" form.
              - >-
                If you don't specify this field but do specify the command field, then the command from the `command` field runs without any additional

                arguments.
              - >-
                See the [Kubernetes documentation about how the `command` and `args` fields interact with a container's `ENTRYPOINT` and

                `CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes).
              - >-
                If you don't specify this field and don't specify the `command` field, then the container's

                [`ENTRYPOINT`](https://docs.docker.com/engine/reference/builder/#cmd) and `CMD` determine what runs based on their default behavior.
              - >-
                See the Docker documentation about [how `CMD` and `ENTRYPOINT`

                interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact).
              - >-
                In this field, you can reference [environment variables set by Vertex

                AI](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables) and environment variables set in the

                env field.
              - You cannot reference environment variables set in the Docker image.
              - >-
                In order for environment variables to be expanded, reference them by using the following syntax:$(VARIABLE_NAME) Note that this differs from

                Bash variable expansion, which does not use parentheses.
              - If a variable cannot be resolved, the reference in the input string is used unchanged.
              - >-
                To avoid variable expansion, you can escape this syntax with `$$`; for example:$$(VARIABLE_NAME) This field corresponds to the `args` field

                of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
            elements: str
            type: list
          command:
            description:
              - Specifies the command that runs when the container starts.
              - This overrides the container's [ENTRYPOINT](https://docs.docker.com/engine/reference/builder/#entrypoint).
              - Specify this field as an array of executable and arguments, similar to a Docker `ENTRYPOINT`'s "exec" form, not its "shell" form.
              - >-
                If you do not specify this field, then the container's `ENTRYPOINT` runs, in conjunction with the args field or the container's

                [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd), if either exists.
              - >-
                If this field is not specified and the container does not have an `ENTRYPOINT`, then refer to the Docker documentation about [how `CMD` and

                `ENTRYPOINT` interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact).
              - If you specify this field, then you can also specify the `args` field to provide additional arguments for this command.
              - However, if you specify this field, then the container's `CMD` is ignored.
              - >-
                See the [Kubernetes documentation about how the `command` and `args` fields interact with a container's `ENTRYPOINT` and

                `CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes).
              - >-
                In this field, you can reference [environment variables set by Vertex

                AI](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables) and environment variables set in the

                env field.
              - You cannot reference environment variables set in the Docker image.
              - >-
                In order for environment variables to be expanded, reference them by using the following syntax:$(VARIABLE_NAME) Note that this differs from

                Bash variable expansion, which does not use parentheses.
              - If a variable cannot be resolved, the reference in the input string is used unchanged.
              - >-
                To avoid variable expansion, you can escape this syntax with `$$`; for example:$$(VARIABLE_NAME) This field corresponds to the `command`

                field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
            elements: str
            type: list
          deployment_timeout:
            description:
              - Deployment timeout.
              - Limit for deployment timeout is 2 hours.
            type: str
          env:
            description:
              - List of environment variables to set in the container.
              - After the container starts running, code running in the container can read these environment variables.
              - Additionally, the command and args fields can reference these variables.
              - Later entries in this list can also reference earlier entries.
              - >-
                For example, the following example sets the variable `VAR_2` to have the value `foo bar`: ```json [ { "name": "VAR_1", "value": "foo" }, {

                "name": "VAR_2", "value": "$(VAR_1) bar" } ] ``` If you switch the order of the variables in the example, then the expansion does not occur.
              - >-
                This field corresponds to the `env` field of the Kubernetes Containers [v1 core

                API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
            elements: dict
            suboptions:
              name:
                description:
                  - Name of the environment variable.
                  - Must be a valid C identifier.
                required: true
                type: str
              value:
                description:
                  - >-
                    Variables that reference a $(VAR_NAME) are expanded using the previous defined environment variables in the container and any service

                    environment variables.
                  - If a variable cannot be resolved, the reference in the input string will be unchanged.
                  - 'The $(VAR_NAME) syntax can be escaped with a double $$, ie: $$(VAR_NAME).'
                  - Escaped references will never be expanded, regardless of whether the variable exists or not.
                required: true
                type: str
            type: list
          grpc_ports:
            description:
              - List of ports to expose from the container.
              - Vertex AI sends gRPC prediction requests that it receives to the first port on this list.
              - Vertex AI also sends liveness and health checks to this port.
              - If you do not specify this field, gRPC requests to the container will be disabled.
              - Vertex AI does not use ports other than the first one listed.
              - This field corresponds to the `ports` field of the Kubernetes Containers v1 core API.
            elements: dict
            suboptions:
              container_port:
                description:
                  - The number of the port to expose on the pod's IP address.
                  - Must be a valid port number, between 1 and 65535 inclusive.
                type: int
            type: list
          health_probe:
            description:
              - Probe describes a health check to be performed against a container to determine whether it is alive or ready to receive traffic.
            suboptions:
              exec:
                description:
                  - ExecAction specifies a command to execute.
                suboptions:
                  command:
                    description:
                      - >-
                        Command is the command line to execute inside the container, the working directory for the command is root ('/') in the container's

                        filesystem.
                      - The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work.
                      - To use a shell, you need to explicitly call out to that shell.
                      - Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
                    elements: str
                    type: list
                type: dict
              failure_threshold:
                description:
                  - Number of consecutive failures before the probe is considered failed.
                  - Defaults to 3.
                  - Minimum value is 1.
                  - Maps to Kubernetes probe argument 'failureThreshold'.
                type: int
              grpc:
                description:
                  - GrpcAction checks the health of a container using a gRPC service.
                suboptions:
                  port:
                    description:
                      - Port number of the gRPC service.
                      - Number must be in the range 1 to 65535.
                    type: int
                  service:
                    description:
                      - Service is the name of the service to place in the gRPC HealthCheckRequest.
                      - See https://github.com/grpc/grpc/blob/master/doc/health-checking.md.
                      - If this is not specified, the default behavior is defined by gRPC.
                    type: str
                type: dict
              http_get:
                description:
                  - HttpGetAction describes an action based on HTTP Get requests.
                suboptions:
                  host:
                    description:
                      - Host name to connect to, defaults to the model serving container's IP.
                      - You probably want to set "Host" in httpHeaders instead.
                    type: str
                  http_headers:
                    description:
                      - Custom headers to set in the request.
                      - HTTP allows repeated headers.
                    elements: dict
                    suboptions:
                      name:
                        description:
                          - The header field name.
                          - This will be canonicalized upon output, so case-variant names will be understood as the same header.
                        type: str
                      value:
                        description:
                          - The header field value.
                        type: str
                    type: list
                  path:
                    description:
                      - Path to access on the HTTP server.
                    type: str
                  port:
                    description:
                      - Number of the port to access on the container.
                      - Number must be in the range 1 to 65535.
                    type: int
                  scheme:
                    description:
                      - Scheme to use for connecting to the host.
                      - Defaults to HTTP.
                      - Acceptable values are "HTTP" or "HTTPS".
                    type: str
                type: dict
              initial_delay_seconds:
                description:
                  - Number of seconds to wait before starting the probe.
                  - Defaults to 0.
                  - Minimum value is 0.
                  - Maps to Kubernetes probe argument 'initialDelaySeconds'.
                type: int
              period_seconds:
                description:
                  - How often (in seconds) to perform the probe.
                  - Default to 10 seconds.
                  - Minimum value is 1.
                  - Must be less than timeout_seconds.
                  - Maps to Kubernetes probe argument 'periodSeconds'.
                type: int
              success_threshold:
                description:
                  - Number of consecutive successes before the probe is considered successful.
                  - Defaults to 1.
                  - Minimum value is 1.
                  - Maps to Kubernetes probe argument 'successThreshold'.
                type: int
              tcp_socket:
                description:
                  - TcpSocketAction probes the health of a container by opening a TCP socket connection.
                suboptions:
                  host:
                    description:
                      - 'Optional: Host name to connect to, defaults to the model serving container''s IP.'
                    type: str
                  port:
                    description:
                      - Number of the port to access on the container.
                      - Number must be in the range 1 to 65535.
                    type: int
                type: dict
              timeout_seconds:
                description:
                  - Number of seconds after which the probe times out.
                  - Defaults to 1 second.
                  - Minimum value is 1.
                  - Must be greater or equal to period_seconds.
                  - Maps to Kubernetes probe argument 'timeoutSeconds'.
                type: int
            type: dict
          health_route:
            description:
              - HTTP path on the container to send health checks to.
              - Vertex AI intermittently sends GET requests to this path on the container's IP address and port to check that the container is healthy.
              - Read more about [health checks](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#health).
              - >-
                For example, if you set this field to `/bar`, then Vertex AI intermittently sends a GET request to the `/bar` path on the port of your

                container specified by the first value of this `ModelContainerSpec`'s ports field.
              - >-
                If you don't specify this field, it defaults to the following value when you deploy this Model to an

                Endpoint:/v1/endpoints/ENDPOINT/deployedModels/DEPLOYED_MODEL:predict The placeholders in this value are replaced as follows: * ENDPOINT:

                The last segment (following `endpoints/`)of the Endpoint.name][] field of the Endpoint where this Model has been deployed.
              - >-
                (Vertex AI makes this value available to your container code as the [`AIP_ENDPOINT_ID` environment

                variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).) * DEPLOYED_MODEL:

                DeployedModel.id of the `DeployedModel`.
              - >-
                (Vertex AI makes this value available to your container code as the [`AIP_DEPLOYED_MODEL_ID` environment

                variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).).
            type: str
          image_uri:
            description:
              - URI of the Docker image to be used as the custom container for serving predictions.
              - This URI must identify an image in Artifact Registry or Container Registry.
              - >-
                Learn more about the [container publishing

                requirements](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#publishing), including permissions

                requirements for the Vertex AI Service Agent.
              - The container image is ingested upon ModelService.UploadModel, stored internally, and this original path is afterwards not used.
              - >-
                To learn about the requirements for the Docker image itself, see [Custom container

                requirements](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#).
              - >-
                You can use the URI to one of Vertex AI's [pre-built container images for

                prediction](https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers) in this field.
            required: true
            type: str
          liveness_probe:
            description:
              - Probe describes a health check to be performed against a container to determine whether it is alive or ready to receive traffic.
            suboptions:
              exec:
                description:
                  - ExecAction specifies a command to execute.
                suboptions:
                  command:
                    description:
                      - >-
                        Command is the command line to execute inside the container, the working directory for the command is root ('/') in the container's

                        filesystem.
                      - The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work.
                      - To use a shell, you need to explicitly call out to that shell.
                      - Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
                    elements: str
                    type: list
                type: dict
              failure_threshold:
                description:
                  - Number of consecutive failures before the probe is considered failed.
                  - Defaults to 3.
                  - Minimum value is 1.
                  - Maps to Kubernetes probe argument 'failureThreshold'.
                type: int
              grpc:
                description:
                  - GrpcAction checks the health of a container using a gRPC service.
                suboptions:
                  port:
                    description:
                      - Port number of the gRPC service.
                      - Number must be in the range 1 to 65535.
                    type: int
                  service:
                    description:
                      - Service is the name of the service to place in the gRPC HealthCheckRequest.
                      - See https://github.com/grpc/grpc/blob/master/doc/health-checking.md.
                      - If this is not specified, the default behavior is defined by gRPC.
                    type: str
                type: dict
              http_get:
                description:
                  - HttpGetAction describes an action based on HTTP Get requests.
                suboptions:
                  host:
                    description:
                      - Host name to connect to, defaults to the model serving container's IP.
                      - You probably want to set "Host" in httpHeaders instead.
                    type: str
                  http_headers:
                    description:
                      - Custom headers to set in the request.
                      - HTTP allows repeated headers.
                    elements: dict
                    suboptions:
                      name:
                        description:
                          - The header field name.
                          - This will be canonicalized upon output, so case-variant names will be understood as the same header.
                        type: str
                      value:
                        description:
                          - The header field value.
                        type: str
                    type: list
                  path:
                    description:
                      - Path to access on the HTTP server.
                    type: str
                  port:
                    description:
                      - Number of the port to access on the container.
                      - Number must be in the range 1 to 65535.
                    type: int
                  scheme:
                    description:
                      - Scheme to use for connecting to the host.
                      - Defaults to HTTP.
                      - Acceptable values are "HTTP" or "HTTPS".
                    type: str
                type: dict
              initial_delay_seconds:
                description:
                  - Number of seconds to wait before starting the probe.
                  - Defaults to 0.
                  - Minimum value is 0.
                  - Maps to Kubernetes probe argument 'initialDelaySeconds'.
                type: int
              period_seconds:
                description:
                  - How often (in seconds) to perform the probe.
                  - Default to 10 seconds.
                  - Minimum value is 1.
                  - Must be less than timeout_seconds.
                  - Maps to Kubernetes probe argument 'periodSeconds'.
                type: int
              success_threshold:
                description:
                  - Number of consecutive successes before the probe is considered successful.
                  - Defaults to 1.
                  - Minimum value is 1.
                  - Maps to Kubernetes probe argument 'successThreshold'.
                type: int
              tcp_socket:
                description:
                  - TcpSocketAction probes the health of a container by opening a TCP socket connection.
                suboptions:
                  host:
                    description:
                      - 'Optional: Host name to connect to, defaults to the model serving container''s IP.'
                    type: str
                  port:
                    description:
                      - Number of the port to access on the container.
                      - Number must be in the range 1 to 65535.
                    type: int
                type: dict
              timeout_seconds:
                description:
                  - Number of seconds after which the probe times out.
                  - Defaults to 1 second.
                  - Minimum value is 1.
                  - Must be greater or equal to period_seconds.
                  - Maps to Kubernetes probe argument 'timeoutSeconds'.
                type: int
            type: dict
          ports:
            description:
              - List of ports to expose from the container.
              - Vertex AI sends any prediction requests that it receives to the first port on this list.
              - >-
                Vertex AI also sends [liveness and health

                checks](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#liveness) to this port.
              - >-
                If you do not specify this field, it defaults to following value: ```json [ { "containerPort": 8080 } ] ``` Vertex AI does not use ports

                other than the first one listed.
              - >-
                This field corresponds to the `ports` field of the Kubernetes Containers [v1 core

                API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
            elements: dict
            suboptions:
              container_port:
                description:
                  - The number of the port to expose on the pod's IP address.
                  - Must be a valid port number, between 1 and 65535 inclusive.
                type: int
            type: list
          predict_route:
            description:
              - HTTP path on the container to send prediction requests to.
              - Vertex AI forwards requests sent using projects.locations.endpoints.predict to this path on the container's IP address and port.
              - Vertex AI then returns the container's response in the API response.
              - >-
                For example, if you set this field to `/foo`, then when Vertex AI receives a prediction request, it forwards the request body in a POST

                request to the `/foo` path on the port of your container specified by the first value of this `ModelContainerSpec`'s ports field.
              - >-
                If you don't specify this field, it defaults to the following value when you deploy this Model to an

                Endpoint:/v1/endpoints/ENDPOINT/deployedModels/DEPLOYED_MODEL:predict The placeholders in this value are replaced as follows: * ENDPOINT:

                The last segment (following `endpoints/`)of the Endpoint.name][] field of the Endpoint where this Model has been deployed.
              - >-
                (Vertex AI makes this value available to your container code as the [`AIP_ENDPOINT_ID` environment

                variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).) * DEPLOYED_MODEL:

                DeployedModel.id of the `DeployedModel`.
              - >-
                (Vertex AI makes this value available to your container code as the [`AIP_DEPLOYED_MODEL_ID` environment

                variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).).
            type: str
          shared_memory_size_mb:
            description:
              - The amount of the VM memory to reserve as the shared memory for the model in megabytes.
            type: str
          startup_probe:
            description:
              - Probe describes a health check to be performed against a container to determine whether it is alive or ready to receive traffic.
            suboptions:
              exec:
                description:
                  - ExecAction specifies a command to execute.
                suboptions:
                  command:
                    description:
                      - >-
                        Command is the command line to execute inside the container, the working directory for the command is root ('/') in the container's

                        filesystem.
                      - The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work.
                      - To use a shell, you need to explicitly call out to that shell.
                      - Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
                    elements: str
                    type: list
                type: dict
              failure_threshold:
                description:
                  - Number of consecutive failures before the probe is considered failed.
                  - Defaults to 3.
                  - Minimum value is 1.
                  - Maps to Kubernetes probe argument 'failureThreshold'.
                type: int
              grpc:
                description:
                  - GrpcAction checks the health of a container using a gRPC service.
                suboptions:
                  port:
                    description:
                      - Port number of the gRPC service.
                      - Number must be in the range 1 to 65535.
                    type: int
                  service:
                    description:
                      - Service is the name of the service to place in the gRPC HealthCheckRequest.
                      - See https://github.com/grpc/grpc/blob/master/doc/health-checking.md.
                      - If this is not specified, the default behavior is defined by gRPC.
                    type: str
                type: dict
              http_get:
                description:
                  - HttpGetAction describes an action based on HTTP Get requests.
                suboptions:
                  host:
                    description:
                      - Host name to connect to, defaults to the model serving container's IP.
                      - You probably want to set "Host" in httpHeaders instead.
                    type: str
                  http_headers:
                    description:
                      - Custom headers to set in the request.
                      - HTTP allows repeated headers.
                    elements: dict
                    suboptions:
                      name:
                        description:
                          - The header field name.
                          - This will be canonicalized upon output, so case-variant names will be understood as the same header.
                        type: str
                      value:
                        description:
                          - The header field value.
                        type: str
                    type: list
                  path:
                    description:
                      - Path to access on the HTTP server.
                    type: str
                  port:
                    description:
                      - Number of the port to access on the container.
                      - Number must be in the range 1 to 65535.
                    type: int
                  scheme:
                    description:
                      - Scheme to use for connecting to the host.
                      - Defaults to HTTP.
                      - Acceptable values are "HTTP" or "HTTPS".
                    type: str
                type: dict
              initial_delay_seconds:
                description:
                  - Number of seconds to wait before starting the probe.
                  - Defaults to 0.
                  - Minimum value is 0.
                  - Maps to Kubernetes probe argument 'initialDelaySeconds'.
                type: int
              period_seconds:
                description:
                  - How often (in seconds) to perform the probe.
                  - Default to 10 seconds.
                  - Minimum value is 1.
                  - Must be less than timeout_seconds.
                  - Maps to Kubernetes probe argument 'periodSeconds'.
                type: int
              success_threshold:
                description:
                  - Number of consecutive successes before the probe is considered successful.
                  - Defaults to 1.
                  - Minimum value is 1.
                  - Maps to Kubernetes probe argument 'successThreshold'.
                type: int
              tcp_socket:
                description:
                  - TcpSocketAction probes the health of a container by opening a TCP socket connection.
                suboptions:
                  host:
                    description:
                      - 'Optional: Host name to connect to, defaults to the model serving container''s IP.'
                    type: str
                  port:
                    description:
                      - Number of the port to access on the container.
                      - Number must be in the range 1 to 65535.
                    type: int
                type: dict
              timeout_seconds:
                description:
                  - Number of seconds after which the probe times out.
                  - Defaults to 1 second.
                  - Minimum value is 1.
                  - Must be greater or equal to period_seconds.
                  - Maps to Kubernetes probe argument 'timeoutSeconds'.
                type: int
            type: dict
        type: dict
      hugging_face_access_token:
        description:
          - The Hugging Face read access token used to access the model artifacts of gated models.
        type: str
      hugging_face_cache_enabled:
        description:
          - If true, the model will deploy with a cached version instead of directly downloading the model artifacts from Hugging Face.
          - This is suitable for VPC-SC users with limited internet access.
        type: bool
      model_display_name:
        description:
          - The user-specified display name of the uploaded model.
          - If not set, a default name will be used.
        type: str
    type: dict
  publisher_model_name:
    description:
      - The Model Garden model to deploy.
      - >-
        Format: `publishers/{publisher}/models/{publisher_model}@{version_id}`, or

        `publishers/hf-{hugging-face-author}/models/{hugging-face-model-name}@001`.
    type: str
  state:
    choices:
      - present
      - absent
    default: present
    description:
      - Whether the resource should exist in GCP.
    type: str
requirements:
  - python >= 3.8
  - requests >= 2.18.4
  - google-auth >= 2.25.1
short_description: Creates a GCP VertexAI.EndpointWithModelGardenDeployment resource
"""

EXAMPLES = r"""
- name: Deploy Basic Model
  google.cloud.gcp_vertexai_endpoint_with_model_garden_deployment:
    state: present
    publisher_model_name = publishers/google/models/paligemma@paligemma-224-float32
    endpoint_config:
      endpoint_display_name: my-endpoint
    model_config:
      model_display_name: my-model
      accept_eula: true
    location: us-central1
    project: "{{ gcp_project }}"
    auth_kind: "{{ gcp_cred_kind }}"
    service_account_file: "{{ gcp_cred_file }}"

################################################################################

- name: Deploy Hugging Face Model
  google.cloud.gcp_vertexai_endpoint_with_model_garden_deployment:
    state: present
    hugging_face_model_id: Qwen/Qwen3-0.6B
    endpoint_config:
      endpoint_display_name: huggingface-endpoint
    model_config:
      model_display_name: huggingface-model
      accept_eula: true
    location: us-central1
    project: "{{ gcp_project }}"
    auth_kind: "{{ gcp_cred_kind }}"
    service_account_file: "{{ gcp_cred_file }}"

################################################################################

- name: Deploy Basic Model with PSC Endpoint
  google.cloud.gcp_vertexai_endpoint_with_model_garden_deployment:
    state: present
    publisher_model_name = publishers/google/models/paligemma@paligemma-224-float32
    display_name: my-psc-endoint
    endpoint_config:
      private_service_connect_config:
        enable_private_service_connect: true
        project_allowlist
          - my-project-id
    model_config:
      accept_eula: true
    location: us-central1
    project: "{{ gcp_project }}"
    auth_kind: "{{ gcp_cred_kind }}"
    service_account_file: "{{ gcp_cred_file }}"
"""

RETURN = r"""
changed:
  description: Whether the resource was changed.
  returned: always
  type: bool
deployedModelDisplayName:
  description:
    - Output only.
    - The display name assigned to the model deployed to the endpoint.
    - This is not required to delete the resource but is used for debug logging.
  returned: success
  type: str
deployedModelId:
  description:
    - Output only.
    - The unique numeric ID that Vertex AI assigns to the model at the time it is deployed to the endpoint.
    - >-
      It is required to undeploy the model from the endpoint during resource deletion as described in

      https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.endpoints/undeployModel.
  returned: success
  type: str
state:
  description: The current state of the resource.
  returned: always
  type: str
"""

################################################################################
# Imports
################################################################################

from ansible_collections.google.cloud.plugins.module_utils import gcp_utils as gcp
import types

# BEGIN Custom imports
import copy
import json
import re

# END Custom imports


def build_link(module_params, uri):
    params = module_params.copy()

    return ("https://{region}-aiplatform.googleapis.com/v1/" + uri).format(**params)


class DeployConfig(gcp.Resource):
    def _request(self):
        return {
            "dedicatedResources": gcp.remove_empties(
                DeployConfigDedicatedResources(self.request.get("dedicated_resources", {})).to_request()
            ),  # remove empty values
            "fastTryoutEnabled": self.request.get("fast_tryout_enabled"),
            "systemLabels": self.request.get("system_labels"),
        }

    def _response(self):
        return {
            "dedicatedResources": DeployConfigDedicatedResources().from_response(
                self.response.get("dedicatedResources", {})
            ),
            "fastTryoutEnabled": self.response.get("fastTryoutEnabled"),
            "systemLabels": self.response.get("systemLabels"),
        }


class DeployConfigDedicatedResources(gcp.Resource):
    def _request(self):
        return {
            "autoscalingMetricSpecs": [
                DeployConfigDedicatedResourcesAutoscalingMetricSpec(item).to_request()
                for item in (self.request.get("autoscaling_metric_specs") or [])
            ],
            "machineSpec": gcp.remove_empties(
                DeployConfigDedicatedResourcesMachineSpec(self.request.get("machine_spec", {})).to_request()
            ),  # remove empty values
            "maxReplicaCount": self.request.get("max_replica_count"),
            "minReplicaCount": self.request.get("min_replica_count"),
            "requiredReplicaCount": self.request.get("required_replica_count"),
            "spot": self.request.get("spot"),
        }

    def _response(self):
        return {
            "autoscalingMetricSpecs": [
                DeployConfigDedicatedResourcesAutoscalingMetricSpec().from_response(item)
                for item in (self.response.get("autoscalingMetricSpecs") or [])
            ],
            "machineSpec": DeployConfigDedicatedResourcesMachineSpec().from_response(
                self.response.get("machineSpec", {})
            ),
            "maxReplicaCount": self.response.get("maxReplicaCount"),
            "minReplicaCount": self.response.get("minReplicaCount"),
            "requiredReplicaCount": self.response.get("requiredReplicaCount"),
            "spot": self.response.get("spot"),
        }


class DeployConfigDedicatedResourcesAutoscalingMetricSpec(gcp.Resource):
    def _request(self):
        return {
            "metricName": self.request.get("metric_name"),
            "target": self.request.get("target"),
        }

    def _response(self):
        return {
            "metricName": self.response.get("metricName"),
            "target": self.response.get("target"),
        }


class DeployConfigDedicatedResourcesMachineSpec(gcp.Resource):
    def _request(self):
        return {
            "acceleratorCount": self.request.get("accelerator_count"),
            "acceleratorType": self.request.get("accelerator_type"),
            "machineType": self.request.get("machine_type"),
            "multihostGpuNodeCount": self.request.get("multihost_gpu_node_count"),
            "reservationAffinity": gcp.remove_empties(
                DeployConfigDedicatedResourcesMachineSpecReservationAffinity(
                    self.request.get("reservation_affinity", {})
                ).to_request()
            ),  # remove empty values
            "tpuTopology": self.request.get("tpu_topology"),
        }

    def _response(self):
        return {
            "acceleratorCount": self.response.get("acceleratorCount"),
            "acceleratorType": self.response.get("acceleratorType"),
            "machineType": self.response.get("machineType"),
            "multihostGpuNodeCount": self.response.get("multihostGpuNodeCount"),
            "reservationAffinity": DeployConfigDedicatedResourcesMachineSpecReservationAffinity().from_response(
                self.response.get("reservationAffinity", {})
            ),
            "tpuTopology": self.response.get("tpuTopology"),
        }


class DeployConfigDedicatedResourcesMachineSpecReservationAffinity(gcp.Resource):
    def _request(self):
        return {
            "key": self.request.get("key"),
            "reservationAffinityType": self.request.get("reservation_affinity_type"),
            "values": self.request.get("values"),
        }

    def _response(self):
        return {
            "key": self.response.get("key"),
            "reservationAffinityType": self.response.get("reservationAffinityType"),
            "values": self.response.get("values"),
        }


class EndpointConfig(gcp.Resource):
    def _request(self):
        return {
            "dedicatedEndpointEnabled": self.request.get("dedicated_endpoint_enabled"),
            "endpointDisplayName": self.request.get("endpoint_display_name"),
            "privateServiceConnectConfig": gcp.remove_empties(
                EndpointConfigPrivateServiceConnectConfig(
                    self.request.get("private_service_connect_config", {})
                ).to_request()
            ),  # remove empty values
        }

    def _response(self):
        return {
            "dedicatedEndpointEnabled": self.response.get("dedicatedEndpointEnabled"),
            "endpointDisplayName": self.response.get("endpointDisplayName"),
            "privateServiceConnectConfig": EndpointConfigPrivateServiceConnectConfig().from_response(
                self.response.get("privateServiceConnectConfig", {})
            ),
        }


class EndpointConfigPrivateServiceConnectConfig(gcp.Resource):
    def _request(self):
        return {
            "enablePrivateServiceConnect": self.request.get("enable_private_service_connect"),
            "projectAllowlist": self.request.get("project_allowlist"),
            "pscAutomationConfigs": gcp.remove_empties(
                EndpointConfigPrivateServiceConnectConfigPscAutomationConfigs(
                    self.request.get("psc_automation_configs", {})
                ).to_request()
            ),  # remove empty values
        }

    def _response(self):
        return {
            "enablePrivateServiceConnect": self.response.get("enablePrivateServiceConnect"),
            "projectAllowlist": self.response.get("projectAllowlist"),
            "pscAutomationConfigs": EndpointConfigPrivateServiceConnectConfigPscAutomationConfigs().from_response(
                self.response.get("pscAutomationConfigs", {})
            ),
            "serviceAttachment": self.response.get("serviceAttachment"),
        }


class EndpointConfigPrivateServiceConnectConfigPscAutomationConfigs(gcp.Resource):
    def _request(self):
        return {
            "network": self.request.get("network"),
            "projectId": self.request.get("project_id"),
        }

    def _response(self):
        return {
            "errorMessage": self.response.get("errorMessage"),
            "forwardingRule": self.response.get("forwardingRule"),
            "ipAddress": self.response.get("ipAddress"),
            "network": self.response.get("network"),
            "projectId": self.response.get("projectId"),
            "state": self.response.get("state"),
        }


class ModelConfig(gcp.Resource):
    def _request(self):
        return {
            "acceptEula": self.request.get("accept_eula"),
            "containerSpec": gcp.remove_empties(
                ModelConfigContainerSpec(self.request.get("container_spec", {})).to_request()
            ),  # remove empty values
            "huggingFaceAccessToken": self.request.get("hugging_face_access_token"),
            "huggingFaceCacheEnabled": self.request.get("hugging_face_cache_enabled"),
            "modelDisplayName": self.request.get("model_display_name"),
        }

    def _response(self):
        return {
            "acceptEula": self.response.get("acceptEula"),
            "containerSpec": ModelConfigContainerSpec().from_response(self.response.get("containerSpec", {})),
            "huggingFaceAccessToken": self.response.get("huggingFaceAccessToken"),
            "huggingFaceCacheEnabled": self.response.get("huggingFaceCacheEnabled"),
            "modelDisplayName": self.response.get("modelDisplayName"),
        }


class ModelConfigContainerSpec(gcp.Resource):
    def _request(self):
        return {
            "args": self.request.get("args"),
            "command": self.request.get("command"),
            "deploymentTimeout": self.request.get("deployment_timeout"),
            "env": [ModelConfigContainerSpecEnv(item).to_request() for item in (self.request.get("env") or [])],
            "grpcPorts": [
                ModelConfigContainerSpecGrpcPort(item).to_request() for item in (self.request.get("grpc_ports") or [])
            ],
            "healthProbe": gcp.remove_empties(
                ModelConfigContainerSpecHealthProbe(self.request.get("health_probe", {})).to_request()
            ),  # remove empty values
            "healthRoute": self.request.get("health_route"),
            "imageUri": self.request.get("image_uri"),
            "livenessProbe": gcp.remove_empties(
                ModelConfigContainerSpecLivenessProbe(self.request.get("liveness_probe", {})).to_request()
            ),  # remove empty values
            "ports": [ModelConfigContainerSpecPort(item).to_request() for item in (self.request.get("ports") or [])],
            "predictRoute": self.request.get("predict_route"),
            "sharedMemorySizeMb": self.request.get("shared_memory_size_mb"),
            "startupProbe": gcp.remove_empties(
                ModelConfigContainerSpecStartupProbe(self.request.get("startup_probe", {})).to_request()
            ),  # remove empty values
        }

    def _response(self):
        return {
            "args": self.response.get("args"),
            "command": self.response.get("command"),
            "deploymentTimeout": self.response.get("deploymentTimeout"),
            "env": [ModelConfigContainerSpecEnv().from_response(item) for item in (self.response.get("env") or [])],
            "grpcPorts": [
                ModelConfigContainerSpecGrpcPort().from_response(item)
                for item in (self.response.get("grpcPorts") or [])
            ],
            "healthProbe": ModelConfigContainerSpecHealthProbe().from_response(self.response.get("healthProbe", {})),
            "healthRoute": self.response.get("healthRoute"),
            "imageUri": self.response.get("imageUri"),
            "livenessProbe": ModelConfigContainerSpecLivenessProbe().from_response(
                self.response.get("livenessProbe", {})
            ),
            "ports": [
                ModelConfigContainerSpecPort().from_response(item) for item in (self.response.get("ports") or [])
            ],
            "predictRoute": self.response.get("predictRoute"),
            "sharedMemorySizeMb": self.response.get("sharedMemorySizeMb"),
            "startupProbe": ModelConfigContainerSpecStartupProbe().from_response(self.response.get("startupProbe", {})),
        }


class ModelConfigContainerSpecEnv(gcp.Resource):
    def _request(self):
        return {
            "name": self.request.get("name"),
            "value": self.request.get("value"),
        }

    def _response(self):
        return {
            "name": self.response.get("name"),
            "value": self.response.get("value"),
        }


class ModelConfigContainerSpecGrpcPort(gcp.Resource):
    def _request(self):
        return {
            "containerPort": self.request.get("container_port"),
        }

    def _response(self):
        return {
            "containerPort": self.response.get("containerPort"),
        }


class ModelConfigContainerSpecHealthProbe(gcp.Resource):
    def _request(self):
        return {
            "exec": gcp.remove_empties(
                ModelConfigContainerSpecHealthProbeExec(self.request.get("exec", {})).to_request()
            ),  # remove empty values
            "failureThreshold": self.request.get("failure_threshold"),
            "grpc": gcp.remove_empties(
                ModelConfigContainerSpecHealthProbeGrpc(self.request.get("grpc", {})).to_request()
            ),  # remove empty values
            "httpGet": gcp.remove_empties(
                ModelConfigContainerSpecHealthProbeHttpGet(self.request.get("http_get", {})).to_request()
            ),  # remove empty values
            "initialDelaySeconds": self.request.get("initial_delay_seconds"),
            "periodSeconds": self.request.get("period_seconds"),
            "successThreshold": self.request.get("success_threshold"),
            "tcpSocket": gcp.remove_empties(
                ModelConfigContainerSpecHealthProbeTcpSocket(self.request.get("tcp_socket", {})).to_request()
            ),  # remove empty values
            "timeoutSeconds": self.request.get("timeout_seconds"),
        }

    def _response(self):
        return {
            "exec": ModelConfigContainerSpecHealthProbeExec().from_response(self.response.get("exec", {})),
            "failureThreshold": self.response.get("failureThreshold"),
            "grpc": ModelConfigContainerSpecHealthProbeGrpc().from_response(self.response.get("grpc", {})),
            "httpGet": ModelConfigContainerSpecHealthProbeHttpGet().from_response(self.response.get("httpGet", {})),
            "initialDelaySeconds": self.response.get("initialDelaySeconds"),
            "periodSeconds": self.response.get("periodSeconds"),
            "successThreshold": self.response.get("successThreshold"),
            "tcpSocket": ModelConfigContainerSpecHealthProbeTcpSocket().from_response(
                self.response.get("tcpSocket", {})
            ),
            "timeoutSeconds": self.response.get("timeoutSeconds"),
        }


class ModelConfigContainerSpecHealthProbeExec(gcp.Resource):
    def _request(self):
        return {
            "command": self.request.get("command"),
        }

    def _response(self):
        return {
            "command": self.response.get("command"),
        }


class ModelConfigContainerSpecHealthProbeGrpc(gcp.Resource):
    def _request(self):
        return {
            "port": self.request.get("port"),
            "service": self.request.get("service"),
        }

    def _response(self):
        return {
            "port": self.response.get("port"),
            "service": self.response.get("service"),
        }


class ModelConfigContainerSpecHealthProbeHttpGet(gcp.Resource):
    def _request(self):
        return {
            "host": self.request.get("host"),
            "httpHeaders": [
                ModelConfigContainerSpecHealthProbeHttpGetHttpHeader(item).to_request()
                for item in (self.request.get("http_headers") or [])
            ],
            "path": self.request.get("path"),
            "port": self.request.get("port"),
            "scheme": self.request.get("scheme"),
        }

    def _response(self):
        return {
            "host": self.response.get("host"),
            "httpHeaders": [
                ModelConfigContainerSpecHealthProbeHttpGetHttpHeader().from_response(item)
                for item in (self.response.get("httpHeaders") or [])
            ],
            "path": self.response.get("path"),
            "port": self.response.get("port"),
            "scheme": self.response.get("scheme"),
        }


class ModelConfigContainerSpecHealthProbeHttpGetHttpHeader(gcp.Resource):
    def _request(self):
        return {
            "name": self.request.get("name"),
            "value": self.request.get("value"),
        }

    def _response(self):
        return {
            "name": self.response.get("name"),
            "value": self.response.get("value"),
        }


class ModelConfigContainerSpecHealthProbeTcpSocket(gcp.Resource):
    def _request(self):
        return {
            "host": self.request.get("host"),
            "port": self.request.get("port"),
        }

    def _response(self):
        return {
            "host": self.response.get("host"),
            "port": self.response.get("port"),
        }


class ModelConfigContainerSpecLivenessProbe(gcp.Resource):
    def _request(self):
        return {
            "exec": gcp.remove_empties(
                ModelConfigContainerSpecLivenessProbeExec(self.request.get("exec", {})).to_request()
            ),  # remove empty values
            "failureThreshold": self.request.get("failure_threshold"),
            "grpc": gcp.remove_empties(
                ModelConfigContainerSpecLivenessProbeGrpc(self.request.get("grpc", {})).to_request()
            ),  # remove empty values
            "httpGet": gcp.remove_empties(
                ModelConfigContainerSpecLivenessProbeHttpGet(self.request.get("http_get", {})).to_request()
            ),  # remove empty values
            "initialDelaySeconds": self.request.get("initial_delay_seconds"),
            "periodSeconds": self.request.get("period_seconds"),
            "successThreshold": self.request.get("success_threshold"),
            "tcpSocket": gcp.remove_empties(
                ModelConfigContainerSpecLivenessProbeTcpSocket(self.request.get("tcp_socket", {})).to_request()
            ),  # remove empty values
            "timeoutSeconds": self.request.get("timeout_seconds"),
        }

    def _response(self):
        return {
            "exec": ModelConfigContainerSpecLivenessProbeExec().from_response(self.response.get("exec", {})),
            "failureThreshold": self.response.get("failureThreshold"),
            "grpc": ModelConfigContainerSpecLivenessProbeGrpc().from_response(self.response.get("grpc", {})),
            "httpGet": ModelConfigContainerSpecLivenessProbeHttpGet().from_response(self.response.get("httpGet", {})),
            "initialDelaySeconds": self.response.get("initialDelaySeconds"),
            "periodSeconds": self.response.get("periodSeconds"),
            "successThreshold": self.response.get("successThreshold"),
            "tcpSocket": ModelConfigContainerSpecLivenessProbeTcpSocket().from_response(
                self.response.get("tcpSocket", {})
            ),
            "timeoutSeconds": self.response.get("timeoutSeconds"),
        }


class ModelConfigContainerSpecLivenessProbeExec(gcp.Resource):
    def _request(self):
        return {
            "command": self.request.get("command"),
        }

    def _response(self):
        return {
            "command": self.response.get("command"),
        }


class ModelConfigContainerSpecLivenessProbeGrpc(gcp.Resource):
    def _request(self):
        return {
            "port": self.request.get("port"),
            "service": self.request.get("service"),
        }

    def _response(self):
        return {
            "port": self.response.get("port"),
            "service": self.response.get("service"),
        }


class ModelConfigContainerSpecLivenessProbeHttpGet(gcp.Resource):
    def _request(self):
        return {
            "host": self.request.get("host"),
            "httpHeaders": [
                ModelConfigContainerSpecLivenessProbeHttpGetHttpHeader(item).to_request()
                for item in (self.request.get("http_headers") or [])
            ],
            "path": self.request.get("path"),
            "port": self.request.get("port"),
            "scheme": self.request.get("scheme"),
        }

    def _response(self):
        return {
            "host": self.response.get("host"),
            "httpHeaders": [
                ModelConfigContainerSpecLivenessProbeHttpGetHttpHeader().from_response(item)
                for item in (self.response.get("httpHeaders") or [])
            ],
            "path": self.response.get("path"),
            "port": self.response.get("port"),
            "scheme": self.response.get("scheme"),
        }


class ModelConfigContainerSpecLivenessProbeHttpGetHttpHeader(gcp.Resource):
    def _request(self):
        return {
            "name": self.request.get("name"),
            "value": self.request.get("value"),
        }

    def _response(self):
        return {
            "name": self.response.get("name"),
            "value": self.response.get("value"),
        }


class ModelConfigContainerSpecLivenessProbeTcpSocket(gcp.Resource):
    def _request(self):
        return {
            "host": self.request.get("host"),
            "port": self.request.get("port"),
        }

    def _response(self):
        return {
            "host": self.response.get("host"),
            "port": self.response.get("port"),
        }


class ModelConfigContainerSpecPort(gcp.Resource):
    def _request(self):
        return {
            "containerPort": self.request.get("container_port"),
        }

    def _response(self):
        return {
            "containerPort": self.response.get("containerPort"),
        }


class ModelConfigContainerSpecStartupProbe(gcp.Resource):
    def _request(self):
        return {
            "exec": gcp.remove_empties(
                ModelConfigContainerSpecStartupProbeExec(self.request.get("exec", {})).to_request()
            ),  # remove empty values
            "failureThreshold": self.request.get("failure_threshold"),
            "grpc": gcp.remove_empties(
                ModelConfigContainerSpecStartupProbeGrpc(self.request.get("grpc", {})).to_request()
            ),  # remove empty values
            "httpGet": gcp.remove_empties(
                ModelConfigContainerSpecStartupProbeHttpGet(self.request.get("http_get", {})).to_request()
            ),  # remove empty values
            "initialDelaySeconds": self.request.get("initial_delay_seconds"),
            "periodSeconds": self.request.get("period_seconds"),
            "successThreshold": self.request.get("success_threshold"),
            "tcpSocket": gcp.remove_empties(
                ModelConfigContainerSpecStartupProbeTcpSocket(self.request.get("tcp_socket", {})).to_request()
            ),  # remove empty values
            "timeoutSeconds": self.request.get("timeout_seconds"),
        }

    def _response(self):
        return {
            "exec": ModelConfigContainerSpecStartupProbeExec().from_response(self.response.get("exec", {})),
            "failureThreshold": self.response.get("failureThreshold"),
            "grpc": ModelConfigContainerSpecStartupProbeGrpc().from_response(self.response.get("grpc", {})),
            "httpGet": ModelConfigContainerSpecStartupProbeHttpGet().from_response(self.response.get("httpGet", {})),
            "initialDelaySeconds": self.response.get("initialDelaySeconds"),
            "periodSeconds": self.response.get("periodSeconds"),
            "successThreshold": self.response.get("successThreshold"),
            "tcpSocket": ModelConfigContainerSpecStartupProbeTcpSocket().from_response(
                self.response.get("tcpSocket", {})
            ),
            "timeoutSeconds": self.response.get("timeoutSeconds"),
        }


class ModelConfigContainerSpecStartupProbeExec(gcp.Resource):
    def _request(self):
        return {
            "command": self.request.get("command"),
        }

    def _response(self):
        return {
            "command": self.response.get("command"),
        }


class ModelConfigContainerSpecStartupProbeGrpc(gcp.Resource):
    def _request(self):
        return {
            "port": self.request.get("port"),
            "service": self.request.get("service"),
        }

    def _response(self):
        return {
            "port": self.response.get("port"),
            "service": self.response.get("service"),
        }


class ModelConfigContainerSpecStartupProbeHttpGet(gcp.Resource):
    def _request(self):
        return {
            "host": self.request.get("host"),
            "httpHeaders": [
                ModelConfigContainerSpecStartupProbeHttpGetHttpHeader(item).to_request()
                for item in (self.request.get("http_headers") or [])
            ],
            "path": self.request.get("path"),
            "port": self.request.get("port"),
            "scheme": self.request.get("scheme"),
        }

    def _response(self):
        return {
            "host": self.response.get("host"),
            "httpHeaders": [
                ModelConfigContainerSpecStartupProbeHttpGetHttpHeader().from_response(item)
                for item in (self.response.get("httpHeaders") or [])
            ],
            "path": self.response.get("path"),
            "port": self.response.get("port"),
            "scheme": self.response.get("scheme"),
        }


class ModelConfigContainerSpecStartupProbeHttpGetHttpHeader(gcp.Resource):
    def _request(self):
        return {
            "name": self.request.get("name"),
            "value": self.request.get("value"),
        }

    def _response(self):
        return {
            "name": self.response.get("name"),
            "value": self.response.get("value"),
        }


class ModelConfigContainerSpecStartupProbeTcpSocket(gcp.Resource):
    def _request(self):
        return {
            "host": self.request.get("host"),
            "port": self.request.get("port"),
        }

    def _response(self):
        return {
            "host": self.response.get("host"),
            "port": self.response.get("port"),
        }


class VertexAI(gcp.Resource):
    def _request(self):
        return {
            "deployConfig": gcp.remove_empties(
                DeployConfig(self.request.get("deploy_config", {})).to_request()
            ),  # remove empty values
            "endpointConfig": gcp.remove_empties(
                EndpointConfig(self.request.get("endpoint_config", {})).to_request()
            ),  # remove empty values
            "huggingFaceModelId": self.request.get("hugging_face_model_id"),
            "modelConfig": gcp.remove_empties(
                ModelConfig(self.request.get("model_config", {})).to_request()
            ),  # remove empty values
            "publisherModelName": self.request.get("publisher_model_name"),
        }

    def _response(self):
        return {
            "deployConfig": DeployConfig().from_response(self.response.get("deployConfig", {})),
            "deployedModelDisplayName": self.response.get("deployedModelDisplayName"),
            "deployedModelId": self.response.get("deployedModelId"),
            "endpointConfig": EndpointConfig().from_response(self.response.get("endpointConfig", {})),
            "huggingFaceModelId": self.response.get("huggingFaceModelId"),
            "modelConfig": ModelConfig().from_response(self.response.get("modelConfig", {})),
            "publisherModelName": self.response.get("publisherModelName"),
        }


################################################################################
# Main
################################################################################


def encode(self, obj):
    """
    This is a function bound to the main resource object. Its input is the object returned from to_request()
    and it mutates it before it is sent to the API.
    """
    return obj


def decode(self, obj):
    """
    This is a function bound to the main resource object. Its input is the object returned from from_response()
    and it mutates it before it is returned to the module caller.
    """
    return obj


def main():
    """Main function"""

    module = gcp.Module(
        argument_spec=dict(
            state=dict(
                type="str",
                default="present",
                choices=["present", "absent"],
            ),
            deploy_config=dict(
                type="dict",
                options=dict(
                    dedicated_resources=dict(
                        type="dict",
                        options=dict(
                            autoscaling_metric_specs=dict(
                                type="list",
                                elements="dict",
                                options=dict(
                                    metric_name=dict(
                                        type="str",
                                        required=True,
                                    ),
                                    target=dict(
                                        type="int",
                                    ),
                                ),
                            ),
                            machine_spec=dict(
                                type="dict",
                                required=True,
                                options=dict(
                                    accelerator_count=dict(
                                        type="int",
                                    ),
                                    accelerator_type=dict(
                                        type="str",
                                    ),
                                    machine_type=dict(
                                        type="str",
                                    ),
                                    multihost_gpu_node_count=dict(
                                        type="int",
                                    ),
                                    reservation_affinity=dict(
                                        type="dict",
                                        options=dict(
                                            key=dict(
                                                type="str",
                                                no_log=False,
                                            ),
                                            reservation_affinity_type=dict(
                                                type="str",
                                                required=True,
                                            ),
                                            values=dict(
                                                type="list",
                                                elements="str",
                                            ),
                                        ),
                                    ),
                                    tpu_topology=dict(
                                        type="str",
                                    ),
                                ),
                            ),
                            max_replica_count=dict(
                                type="int",
                            ),
                            min_replica_count=dict(
                                type="int",
                                required=True,
                            ),
                            required_replica_count=dict(
                                type="int",
                            ),
                            spot=dict(
                                type="bool",
                            ),
                        ),
                    ),
                    fast_tryout_enabled=dict(
                        type="bool",
                    ),
                    system_labels=dict(
                        type="dict",
                    ),
                ),
            ),
            display_name=dict(
                type="str",
                required=True,
            ),
            endpoint_config=dict(
                type="dict",
                options=dict(
                    dedicated_endpoint_enabled=dict(
                        type="bool",
                    ),
                    endpoint_display_name=dict(
                        type="str",
                    ),
                    private_service_connect_config=dict(
                        type="dict",
                        options=dict(
                            enable_private_service_connect=dict(
                                type="bool",
                                required=True,
                            ),
                            project_allowlist=dict(
                                type="list",
                                elements="str",
                            ),
                            psc_automation_configs=dict(
                                type="dict",
                                options=dict(
                                    error_message=dict(
                                        type="str",
                                    ),
                                    forwarding_rule=dict(
                                        type="str",
                                    ),
                                    ip_address=dict(
                                        type="str",
                                    ),
                                    network=dict(
                                        type="str",
                                        required=True,
                                    ),
                                    project_id=dict(
                                        type="str",
                                        required=True,
                                    ),
                                    state=dict(
                                        type="str",
                                        choices=[
                                            "PSC_AUTOMATION_STATE_UNSPECIFIED",
                                            "PSC_AUTOMATION_STATE_SUCCESSFUL",
                                            "PSC_AUTOMATION_STATE_FAILED",
                                        ],
                                    ),
                                ),
                            ),
                            service_attachment=dict(
                                type="str",
                            ),
                        ),
                    ),
                ),
            ),
            hugging_face_model_id=dict(
                type="str",
            ),
            location=dict(
                type="str",
                required=True,
            ),
            model_config=dict(
                type="dict",
                options=dict(
                    accept_eula=dict(
                        type="bool",
                    ),
                    container_spec=dict(
                        type="dict",
                        options=dict(
                            args=dict(
                                type="list",
                                elements="str",
                            ),
                            command=dict(
                                type="list",
                                elements="str",
                            ),
                            deployment_timeout=dict(
                                type="str",
                            ),
                            env=dict(
                                type="list",
                                elements="dict",
                                options=dict(
                                    name=dict(
                                        type="str",
                                        required=True,
                                    ),
                                    value=dict(
                                        type="str",
                                        required=True,
                                    ),
                                ),
                            ),
                            grpc_ports=dict(
                                type="list",
                                elements="dict",
                                options=dict(
                                    container_port=dict(
                                        type="int",
                                    )
                                ),
                            ),
                            health_probe=dict(
                                type="dict",
                                options=dict(
                                    exec=dict(
                                        type="dict",
                                        options=dict(
                                            command=dict(
                                                type="list",
                                                elements="str",
                                            )
                                        ),
                                    ),
                                    failure_threshold=dict(
                                        type="int",
                                    ),
                                    grpc=dict(
                                        type="dict",
                                        options=dict(
                                            port=dict(
                                                type="int",
                                            ),
                                            service=dict(
                                                type="str",
                                            ),
                                        ),
                                    ),
                                    http_get=dict(
                                        type="dict",
                                        options=dict(
                                            host=dict(
                                                type="str",
                                            ),
                                            http_headers=dict(
                                                type="list",
                                                elements="dict",
                                                options=dict(
                                                    name=dict(
                                                        type="str",
                                                    ),
                                                    value=dict(
                                                        type="str",
                                                    ),
                                                ),
                                            ),
                                            path=dict(
                                                type="str",
                                            ),
                                            port=dict(
                                                type="int",
                                            ),
                                            scheme=dict(
                                                type="str",
                                            ),
                                        ),
                                    ),
                                    initial_delay_seconds=dict(
                                        type="int",
                                    ),
                                    period_seconds=dict(
                                        type="int",
                                    ),
                                    success_threshold=dict(
                                        type="int",
                                    ),
                                    tcp_socket=dict(
                                        type="dict",
                                        options=dict(
                                            host=dict(
                                                type="str",
                                            ),
                                            port=dict(
                                                type="int",
                                            ),
                                        ),
                                    ),
                                    timeout_seconds=dict(
                                        type="int",
                                    ),
                                ),
                            ),
                            health_route=dict(
                                type="str",
                            ),
                            image_uri=dict(
                                type="str",
                                required=True,
                            ),
                            liveness_probe=dict(
                                type="dict",
                                options=dict(
                                    exec=dict(
                                        type="dict",
                                        options=dict(
                                            command=dict(
                                                type="list",
                                                elements="str",
                                            )
                                        ),
                                    ),
                                    failure_threshold=dict(
                                        type="int",
                                    ),
                                    grpc=dict(
                                        type="dict",
                                        options=dict(
                                            port=dict(
                                                type="int",
                                            ),
                                            service=dict(
                                                type="str",
                                            ),
                                        ),
                                    ),
                                    http_get=dict(
                                        type="dict",
                                        options=dict(
                                            host=dict(
                                                type="str",
                                            ),
                                            http_headers=dict(
                                                type="list",
                                                elements="dict",
                                                options=dict(
                                                    name=dict(
                                                        type="str",
                                                    ),
                                                    value=dict(
                                                        type="str",
                                                    ),
                                                ),
                                            ),
                                            path=dict(
                                                type="str",
                                            ),
                                            port=dict(
                                                type="int",
                                            ),
                                            scheme=dict(
                                                type="str",
                                            ),
                                        ),
                                    ),
                                    initial_delay_seconds=dict(
                                        type="int",
                                    ),
                                    period_seconds=dict(
                                        type="int",
                                    ),
                                    success_threshold=dict(
                                        type="int",
                                    ),
                                    tcp_socket=dict(
                                        type="dict",
                                        options=dict(
                                            host=dict(
                                                type="str",
                                            ),
                                            port=dict(
                                                type="int",
                                            ),
                                        ),
                                    ),
                                    timeout_seconds=dict(
                                        type="int",
                                    ),
                                ),
                            ),
                            ports=dict(
                                type="list",
                                elements="dict",
                                options=dict(
                                    container_port=dict(
                                        type="int",
                                    )
                                ),
                            ),
                            predict_route=dict(
                                type="str",
                            ),
                            shared_memory_size_mb=dict(
                                type="str",
                            ),
                            startup_probe=dict(
                                type="dict",
                                options=dict(
                                    exec=dict(
                                        type="dict",
                                        options=dict(
                                            command=dict(
                                                type="list",
                                                elements="str",
                                            )
                                        ),
                                    ),
                                    failure_threshold=dict(
                                        type="int",
                                    ),
                                    grpc=dict(
                                        type="dict",
                                        options=dict(
                                            port=dict(
                                                type="int",
                                            ),
                                            service=dict(
                                                type="str",
                                            ),
                                        ),
                                    ),
                                    http_get=dict(
                                        type="dict",
                                        options=dict(
                                            host=dict(
                                                type="str",
                                            ),
                                            http_headers=dict(
                                                type="list",
                                                elements="dict",
                                                options=dict(
                                                    name=dict(
                                                        type="str",
                                                    ),
                                                    value=dict(
                                                        type="str",
                                                    ),
                                                ),
                                            ),
                                            path=dict(
                                                type="str",
                                            ),
                                            port=dict(
                                                type="int",
                                            ),
                                            scheme=dict(
                                                type="str",
                                            ),
                                        ),
                                    ),
                                    initial_delay_seconds=dict(
                                        type="int",
                                    ),
                                    period_seconds=dict(
                                        type="int",
                                    ),
                                    success_threshold=dict(
                                        type="int",
                                    ),
                                    tcp_socket=dict(
                                        type="dict",
                                        options=dict(
                                            host=dict(
                                                type="str",
                                            ),
                                            port=dict(
                                                type="int",
                                            ),
                                        ),
                                    ),
                                    timeout_seconds=dict(
                                        type="int",
                                    ),
                                ),
                            ),
                        ),
                    ),
                    hugging_face_access_token=dict(
                        type="str",
                        no_log=False,
                    ),
                    hugging_face_cache_enabled=dict(
                        type="bool",
                    ),
                    model_display_name=dict(
                        type="str",
                    ),
                ),
            ),
            publisher_model_name=dict(
                type="str",
            ),
        ),
        mutually_exclusive=[["hugging_face_model_id", "publisher_model_name"]],
        required_one_of=[["hugging_face_model_id", "publisher_model_name"]],
    )

    if not module.params["scopes"]:
        module.params["scopes"] = ["https://www.googleapis.com/auth/cloud-platform"]

    state = module.params["state"]
    changed = False
    op_configs = gcp.ResourceOpConfigs(
        {
            "base_url": gcp.ResourceOpConfig(
                **{
                    "uri": "projects/{project}/locations/{location}:deploy",
                    "async_uri": "",
                    "verb": "GET",
                    "timeout_minutes": 0,
                }
            ),
            "create": gcp.ResourceOpConfig(
                **{
                    "uri": "projects/{project}/locations/{location}:deploy",
                    "async_uri": "{op_id}",
                    "verb": "POST",
                    "timeout_minutes": 180,
                }
            ),
            "delete": gcp.ResourceOpConfig(
                **{
                    "uri": "projects/{project}/locations/{location}/endpoints/{endpoint}",
                    "async_uri": "",
                    "verb": "DELETE",
                    "timeout_minutes": 20,
                }
            ),
            "read": gcp.ResourceOpConfig(
                **{
                    "uri": "projects/{project}/locations/{location}/endpoints/{endpoint}",
                    "async_uri": "",
                    "verb": "GET",
                    "timeout_minutes": 0,
                }
            ),
            "update": gcp.ResourceOpConfig(
                **{
                    "uri": "projects/{project}/locations/{location}/endpoints/{endpoint}",
                    "async_uri": "",
                    "verb": "PUT",
                    "timeout_minutes": 0,
                }
            ),
        }
    )

    params = gcp.remove_nones(module.params)
    resource = VertexAI(params, module=module, product="VertexAI", kind="vertexai#endpointWithModelGardenDeployment")
    read_uri = op_configs.read.uri

    resource._state = state  # store the state in the resource object
    # Bind the encode and decode functions to the resource object
    resource.encode_func = types.MethodType(encode, resource)
    resource.decode_func = types.MethodType(decode, resource)

    custom_diff = None  # Set this variable if you want to implement custom diff logic

    # --------- BEGIN pre-read custom code ---------
    # region and location are the same
    params["region"] = params["location"]

    # need to strip the last part of the read_uri to hit the list endpoint with a filter
    read_uri = "/".join(read_uri.split("/")[:-1])

    display_name = params["display_name"]
    endpoint_display_name = params.get("endpoint_config", {}).get("endpoint_display_name") or display_name
    model_display_name = params.get("model_config", {}).get("model_display_name") or display_name

    # filter by the endpoint display name
    read_uri += f"?filter=displayName={endpoint_display_name}"

    def publisher_model_to_deployed_model(region, path: str) -> str:
        pattern = r"^publishers/(?P<publisher>[^/]+)/models/(?P<model>[^@/]+)(?:@(?P<version>.+))?$"
        match = re.match(pattern, path)
        if match:
            data = match.groupdict()
            data["region"] = region
            if data.get("version") is None:
                data["version"] = "001"
            for key, value in data.items():
                data[key] = re.sub(r"[^a-zA-Z0-9]", "-", value.lower())
            return "locations/{region}/models/{publisher}-{model}-{version}".format(**data)

        return None

    # --------- END pre-read custom code ---------

    read_url = build_link(params, read_uri)
    existing_obj = resource.get(read_url, allow_not_found=True) or {}
    new_obj = {}
    gcp.debug(module, existing=existing_obj, post=False)

    # --------- BEGIN post-read custom code ---------
    outgoing = resource.to_request()

    # if there are existing endpoints, the call would have returned a list
    if not gcp.empty(existing_obj):
        for endpoint in existing_obj.get("endpoints", []):
            if (
                endpoint.get("displayName") == endpoint_display_name
            ):  # filtering should take care of this, but just in case
                existing_obj = endpoint
                existing_obj["endpointDisplayName"] = endpoint.pop("displayName")
                existing_obj["endpoint"] = endpoint.get("name")
                existing_obj["name"] = endpoint.get("endpoint").split("/")[-1]
                break

        for deployed_model in existing_obj.get("deployedModels", []):
            if deployed_model.get("displayName") == model_display_name:
                existing_obj["deployedModelDisplayName"] = deployed_model.pop("displayName")
                existing_obj["deployedModelId"] = deployed_model.get("id")
                existing_obj["deployedModel"] = deployed_model
                break
        else:
            existing_obj["deployedModel"] = {}

        existing_obj.pop("deployedModels", [])

        if existing_obj["deployedModel"]:
            # finally, update the params to build the url
            params["endpoint"] = existing_obj["name"]

            gcp.debug(
                module,
                publisher_model_name=params.get("publisher_model_name"),
                hugging_face_model_id=params.get("hugging_face_model_id"),
            )
            model_to_deploy = params.get("publisher_model_name")  # read publisher model name first
            if model_to_deploy is None:  # if not provided, use the hugging face model id
                model_to_deploy = params.get("hugging_face_model_id")
                hfParts = model_to_deploy.split("/")
                model_to_deploy = (
                    f"publishers/hf-{hfParts[0]}/models/{hfParts[1]}@001"  # put HF model into publisher model format
                )

            model_to_deploy = publisher_model_to_deployed_model(
                params["region"], model_to_deploy
            )  # convert the model id to the deployed model id
            existing_model = existing_obj["deployedModel"].get("model", "")
            # requested model's final name is a substring of the actual deployed model
            gcp.debug(module, model_to_deploy=model_to_deploy, existing_model=existing_model)
            if model_to_deploy in existing_model:  # our outgoing model is a substring the existing model
                custom_diff = False  # deploy model is the same, mark as such
            else:
                custom_diff = True  # deploy model changed, mark as such
        else:
            pass
            # module.fail_json(msg="The endpoint exists but the deployed model does not, delete the endpoint and try again")

    # --------- END post-read custom code ---------

    if custom_diff is not None:
        is_different = custom_diff
    else:
        is_different = resource.diff(gcp.remove_empties(existing_obj))
    gcp.debug(
        module,
        request=gcp.remove_empties(resource.to_request()),
        existing=existing_obj,
        post=True,
        is_different=is_different,
    )

    if gcp.empty(existing_obj):
        if state == "present":
            create_uri = op_configs.create.uri
            create_async_uri = op_configs.create.async_uri
            try:
                # --------- BEGIN create code ---------
                # --------- BEGIN pre-create custom code ---------
                if not params.get("endpoint_config"):
                    params["endpoint_config"] = {}
                if not params["endpoint_config"].get("endpoint_display_name"):
                    params["endpoint_config"]["endpoint_display_name"] = params["display_name"]

                if not params.get("model_config"):
                    params["model_config"] = {}
                if not params["model_config"].get("model_display_name"):
                    params["model_config"]["model_display_name"] = params["display_name"]

                # --------- END pre-create custom code ---------
                is_async = create_async_uri != ""
                create_link = build_link(params, create_uri)
                create_retries = op_configs.create.timeout
                create_func = getattr(resource, op_configs.create.verb)
                async_create_func = getattr(resource, op_configs.create.verb + "_async")
                async_create_link = build_link(params, "") + create_async_uri
                gcp.debug(
                    module,
                    msg="Creating resource",
                    create_link=create_link,
                    async_create_link=async_create_link,
                    is_async=is_async,
                )

                if is_async:
                    new_obj = async_create_func(create_link, async_link=async_create_link, retries=create_retries)
                else:
                    new_obj = create_func(create_link)
                gcp.debug(module, new=new_obj, action="create", post=False)
                # --------- BEGIN post-create custom code ---------
                new_obj["name"] = new_obj.pop("endpoint")

                # --------- END post-create custom code ---------
                gcp.debug(module, new=new_obj, action="create", post=True)
                # --------- END create code ---------
            except Exception as e:
                module.fail_json(msg=str(e))

            changed = True
        else:
            pass  # nothing to do
    else:
        if state == "absent":
            delete_uri = op_configs.delete.uri
            delete_async_uri = op_configs.delete.async_uri
            try:
                # --------- BEGIN delete code ---------
                # --------- BEGIN pre-delete custom code ---------
                params = copy.deepcopy(module.params)
                params["region"] = params["location"]
                params["endpoint"] = existing_obj["name"]

                # First, undeploy the model (if any)
                deployed_model_id = existing_obj.get("deployedModelId")
                # module.exit_json(msg="Deployed model ID: " + deployed_model_id)
                if deployed_model_id:
                    undeploy_url = build_link(params, f"{op_configs.delete.uri}:undeployModel")
                    undeploy_body = {"deployedModelId": deployed_model_id}
                    gcp.debug(module, undeploy_url=undeploy_url, undeploy_body=undeploy_body)
                    # perform an async post to undeploy
                    undeploy_response = resource.session().post(undeploy_url, undeploy_body)
                    try:
                        module.raise_for_status(undeploy_response)
                        undeploy_async_result = undeploy_response.json()
                    except getattr(json.decoder, "JSONDecodeError", ValueError):
                        module.fail_json(msg=f"Invalid JSON response with error: {undeploy_response.text}")
                    params["op_id"] = undeploy_async_result.get("name")
                    async_undeploy_op_link = build_link(params, "{op_id}")
                    gcp.debug(module, params=params, async_undeploy_op_link=async_undeploy_op_link)
                    resource.wait_for_op(async_undeploy_op_link, retries=op_configs.delete.timeout)
                # --------- END pre-delete custom code ---------
                is_async = delete_async_uri != ""
                delete_link = build_link(params, delete_uri)
                delete_retries = op_configs.delete.timeout
                delete_func = getattr(resource, op_configs.delete.verb)
                async_delete_func = getattr(resource, op_configs.delete.verb + "_async")
                async_delete_link = build_link(params, "") + delete_async_uri
                gcp.debug(
                    module,
                    msg="Destroying resource",
                    delete_link=delete_link,
                    async_delete_link=async_delete_link,
                    is_async=is_async,
                )
                if is_async:
                    new_obj = async_delete_func(delete_link, async_link=async_delete_link, retries=delete_retries)
                else:
                    new_obj = delete_func(delete_link)
                # --------- END delete code ---------
            except Exception as e:
                module.fail_json(msg=str(e))

            changed = True
        else:
            if is_different:
                update_uri = op_configs.update.uri
                update_async_uri = op_configs.update.async_uri
                try:
                    # --------- BEGIN update code ---------
                    # --------- BEGIN pre-update custom code ---------
                    module.fail_json(msg="Updating an endpoint with model garden deployment is not supported")

                    # --------- END pre-update custom code ---------
                    is_async = update_async_uri != ""
                    update_link = build_link(params, update_uri)
                    update_retries = op_configs.update.timeout
                    update_func = getattr(resource, op_configs.update.verb)
                    async_update_func = getattr(resource, op_configs.update.verb + "_async")
                    async_update_link = build_link(params, "") + update_async_uri
                    gcp.debug(
                        module,
                        msg="Updating resource",
                        update_link=update_link,
                        async_update_link=async_update_link,
                        is_async=is_async,
                    )
                    if is_async:
                        new_obj = async_update_func(update_link, async_link=async_update_link, retries=update_retries)
                    else:
                        new_obj = update_func(update_link)
                    gcp.debug(module, new=new_obj, action="update", post=False)
                    gcp.debug(module, new=new_obj, action="update", post=True)
                    # --------- END update code ---------
                except Exception as e:
                    module.fail_json(msg=str(e))

                changed = True
            else:
                new_obj = existing_obj

    new_obj.update({"changed": changed})
    module.exit_json(**new_obj)


if __name__ == "__main__":
    main()
